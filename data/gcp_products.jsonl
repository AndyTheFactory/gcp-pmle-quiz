{"product_name":"Vertex AI","entity_type":"Machine Learning Platform","ui":["Google Cloud Console (Web UI)","Vertex AI SDK (Python)","gcloud CLI","REST API","Client Libraries (Java, Node.js, Go)"],"connected_to":["BigQuery","Cloud Storage","Artifact Registry","Container Registry","Cloud Logging","Cloud Monitoring","Dataflow","Pub\/Sub"],"short_description":"Vertex AI is a fully managed, unified artificial intelligence platform that integrates AutoML and custom training options, providing tools for the entire machine learning lifecycle, including feature engineering, training, deployment, MLOps, and access to generative AI models.","use_cases":["Training and deploying custom ML models using containers","Fine-tuning and deploying Generative AI models (LLMs)","Creating end-to-end MLOps pipelines","Using AutoML for rapid model creation on tabular, image, text, or video data","Managing feature stores for real-time serving"],"not_used_when":["You only need off-the-shelf, pre-trained models for standard tasks like OCR or translation (use specific Cloud APIs like Vision API or Translation API instead)","You are performing simple data analysis that can be handled entirely within SQL or a local spreadsheet","You have strict requirements for zero cloud connectivity (unless using Google Distributed Cloud)","Cost minimization is the sole priority for a very low-traffic, simple model that could be hosted on a basic VM or Cloud Run instance without MLOps overhead"]}
{"product_name":"BigQuery ML","entity_type":"Service Feature","ui":["SQL Interface","Google Cloud Console (BigQuery UI)","Command Line Interface (bq tool)","REST API","Client Libraries (Python, Java, etc.)"],"connected_to":["BigQuery","Vertex AI","Cloud Storage","Looker","Google Sheets","Dataflow"],"short_description":"A capability embedded within BigQuery that allows users to create, train, and execute machine learning models on large datasets using standard SQL queries without moving data.","use_cases":["Demand forecasting (Time-series)","Customer churn prediction (Binary classification)","Customer segmentation (K-means clustering)","Product recommendation systems (Matrix factorization)","Fraud detection"],"not_used_when":["Training complex deep learning models on unstructured data (like raw video or complex image processing)","The dataset is very small and fits easily into local memory (using Scikit-learn locally is often cheaper\/faster)","Ultra-low latency real-time inference is required directly from the database (unless the model is exported to Vertex AI)","Highly custom model architectures are needed that are not supported by the BQML library"]}
{"product_name":"Dataflow","entity_type":"Service Feature","ui":["gcloud CLI","Google Cloud Console","REST API"],"connected_to":["Google Cloud Dataflow","Cloud Build","Artifact Registry","Cloud Storage","Apache Beam"],"short_description":"Dataflow Flex Templates allow you to package your Apache Beam pipeline as a Docker image, enabling the separation of pipeline construction from execution and allowing for dynamic graph generation based on runtime parameters.","use_cases":["Pipelines requiring custom dependencies (Python packages or system libraries) installed in the worker environment.","Scenarios where the pipeline graph structure needs to change dynamically based on input parameters.","Implementing CI\/CD pipelines for data processing jobs using containerized artifacts.","Sharing pipeline templates across an organization without exposing the underlying source code."],"not_used_when":["Running simple, one-off ad-hoc jobs where the overhead of building and pushing a Docker container is unjustified.","Local development and unit testing (DirectRunner is preferred).","Strictly low-latency job startup is required (Flex templates have a slight initialization overhead compared to raw job submission, though comparable to Classic templates)."]}
{"product_name":"Pub\/Sub","entity_type":"Managed Service","ui":["Web Console","gcloud CLI","REST API","gRPC API","Client Libraries"],"connected_to":["Cloud Functions","Cloud Run","Dataflow","BigQuery","Cloud Storage","App Engine","Cloud Monitoring"],"short_description":"A fully managed, scalable, global, and asynchronous messaging service used to decouple services that produce events from services that process events.","use_cases":["Ingesting user interaction and server events","Real-time event distribution","Decoupling microservices","Streaming analytics and IoT data ingestion","Asynchronous workflows","Load leveling and buffering"],"not_used_when":["Synchronous, immediate request-response communication is required","Strict First-In-First-Out (FIFO) ordering is required without the specific implementation of ordering keys","Message retention is needed beyond 31 days (long-term storage)","Sub-millisecond latency is critical (e.g., high-frequency trading)"]}
{"product_name":"BigQuery","entity_type":"Analytics Service","ui":["Web Console (Google Cloud Console)","Command Line Interface (bq command-line tool)","REST API","Client Libraries (Python, Java, Go, Node.js, etc.)","ODBC\/JDBC Drivers"],"connected_to":["Cloud Storage","Dataflow","Pub\/Sub","Looker Studio","Vertex AI","Cloud Functions","Dataproc","Cloud Composer"],"short_description":"A fully managed, serverless, and highly scalable enterprise data warehouse that enables super-fast SQL queries across petabytes of data using the processing power of Google's infrastructure.","use_cases":["Enterprise Data Warehousing and migration","Real-time analytics on streaming data","Predictive analytics and machine learning (BigQuery ML)","Business Intelligence (BI) reporting and visualization","Log analysis and security analytics"],"not_used_when":["OLTP (Online Transaction Processing) workloads requiring frequent row-level updates and sub-millisecond latency","Applications requiring a standard relational database backend (like PostgreSQL or MySQL)","Scenarios requiring NoSQL document or wide-column storage for operational data (use Firestore or Bigtable instead)","Handling extremely small datasets where the overhead of a distributed system is unnecessary"]}
{"product_name":"Cloud Data Loss Prevention","entity_type":"Managed Service","ui":["Console UI","REST API","gRPC API","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","BigQuery","Cloud Datastore","Cloud Pub\/Sub","Security Command Center","Data Catalog","Cloud Logging"],"short_description":"A fully managed service designed to discover, classify, and protect sensitive data (such as PII) by inspecting text, images, and storage repositories using predefined or custom detectors.","use_cases":["Redacting or masking PII (Personally Identifiable Information) in text before logging or storage","Scanning Cloud Storage buckets and BigQuery tables for compliance auditing (GDPR, HIPAA, PCI-DSS)","De-identifying production data for use in development or analytics environments","Automating data classification and tagging in Data Catalog"],"not_used_when":["You simply need to encrypt data at rest or in transit without inspecting the content (use Cloud KMS instead)","Processing raw audio or video files directly (data must be converted to text or images first)","Cost is a major constraint for massive datasets and sampling is not an option (full inspection of petabyte-scale data can be expensive)","Ultra-low latency is required for high-frequency real-time applications (network overhead and inspection time may be prohibitive)"]}
{"product_name":"Speech-to-Text API","entity_type":"API","ui":["REST API","gRPC","Google Cloud Console","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","Cloud Functions","Cloud Run","Cloud Natural Language API","Cloud Translation API","Dialogflow"],"short_description":"A managed service that enables developers to convert audio to text by applying powerful neural network models via an API, supporting both real-time streaming and batch processing.","use_cases":["Transcribing customer service calls for analytics","Real-time voice control and commands","Generating captions and subtitles for video content","Dictation features in applications"],"not_used_when":["Strict offline processing is required (unless using the specific On-Prem\/Edge container)","Biometric voice authentication is needed (it performs speaker diarization\/separation, not security verification)","Audio quality is indistinguishable even to the human ear","Zero-cost solutions are required for high volumes"]}
{"product_name":"Vision API","entity_type":"API","ui":["REST API","gRPC","Google Cloud Console","Client Libraries","gcloud CLI"],"connected_to":["Cloud Storage","Cloud Functions","Cloud Run","BigQuery","Dataflow","Vertex AI"],"short_description":"A fully managed service that uses pre-trained machine learning models to derive insights from images, including image labeling, face and landmark detection, optical character recognition (OCR), and explicit content tagging.","use_cases":["Extracting text from scanned documents, PDFs, or images (OCR)","Automated content moderation (SafeSearch detection)","Metadata generation for image catalogs (Label detection)","Detecting faces and emotional attributes","Identifying corporate logos or geographic landmarks"],"not_used_when":["You need to train a model to detect custom objects specific to your niche (use Vertex AI \/ AutoML Vision instead)","You require strictly offline or on-device processing (use ML Kit)","You are analyzing video files (use Cloud Video Intelligence API)","You require facial recognition to identify specific individuals (the API provides face detection, not identification)"]}
{"product_name":"Document AI","entity_type":"Managed Service","ui":["Console UI","REST API","gRPC API","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","BigQuery","Cloud Functions","Workflows","Vertex AI"],"short_description":"A unified console and API platform that uses machine learning to classify, split, and extract structured data from unstructured documents (PDFs, images, forms).","use_cases":["Automating invoice and receipt processing (Procure-to-Pay)","Identity verification using driver licenses and passports","Mortgage document processing (Lending DocAI)","Contract analysis and entity extraction","Digitizing and parsing handwritten forms"],"not_used_when":["The input is already raw text or HTML without visual layout elements (use Cloud Natural Language API instead)","Only simple Optical Character Recognition (OCR) is needed without structural extraction (Cloud Vision API is often more cost-effective)","Ultra-low latency (sub-millisecond) is required for heavy document processing"]}
{"product_name":"TFX","entity_type":"Library \/ SDK","ui":["Python SDK","CLI","Vertex AI Pipelines UI (via integration)","Kubeflow Pipelines UI (via integration)"],"connected_to":["Vertex AI","Cloud Dataflow","Cloud Storage","BigQuery","Kubeflow","TensorFlow Serving","Apache Beam"],"short_description":"An end-to-end platform for deploying production machine learning pipelines, providing pre-built components for data validation, processing, training, evaluation, and serving.","use_cases":["Automating MLOps workflows","Continuous training (CT) and deployment","Large-scale data preprocessing using Apache Beam","Detecting data drift and training-serving skew","Model performance analysis and fairness evaluation"],"not_used_when":["Rapid prototyping or experimentation where pipeline orchestration adds unnecessary overhead","The project is small-scale and does not require rigorous metadata tracking or data validation","Using exclusively non-TensorFlow frameworks (like PyTorch) where native ecosystem tools might be preferred (though TFX can support them via custom components)"]}
{"product_name":"Recommendations AI","entity_type":"Managed Service","ui":["Google Cloud Console","REST API","gRPC","Client Libraries"],"connected_to":["Cloud Storage","BigQuery","Google Analytics","Google Tag Manager","Vertex AI","Retail API"],"short_description":"A fully managed machine learning service that enables retailers to build and deploy high-quality, personalized product recommendation models based on user behavior and catalog data, without requiring deep ML expertise.","use_cases":["E-commerce 'Recommended for you' panels","Shopping cart 'Frequently bought together' suggestions","Personalized home page content","Session-based recommendations for anonymous users","Next-best-offer prediction"],"not_used_when":["You have insufficient historical user event data or catalog size to train a model effectively","You need complete control over the specific ML algorithm or model architecture (use Vertex AI Training instead)","You only require simple, static rule-based filtering without machine learning","The project budget cannot accommodate the pricing of a specialized managed AI service"]}
{"product_name":"AutoML","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Web UI)","REST API","Command Line Interface (gcloud)","Client Libraries (Python, Java, Node.js, etc.)"],"connected_to":["Vertex AI","Cloud Storage","BigQuery","App Engine","Cloud Functions","Cloud Run"],"short_description":"A suite of machine learning products that enables developers with limited ML expertise to train high-quality models specific to their business needs. It automates the transfer learning and neural architecture search processes to create custom models for vision, video, language, and tabular data.","use_cases":["Classifying images with custom labels (e.g., identifying specific manufacturing defects)","Extracting custom entities from text documents","Predicting values or categories based on structured tabular data (regression\/classification)","Translating content with domain-specific vocabulary","Object detection in video streams"],"not_used_when":["You need complete control over model architecture, layers, and hyperparameters","The standard pre-trained Google Cloud APIs (Vision API, Natural Language API) already solve the problem with sufficient accuracy","You have a very limited training budget (AutoML training hours can be expensive compared to custom training on small instances)","You do not have enough labeled data to meet the minimum requirements for training","Real-time inference latency requirements are extremely strict and require highly optimized, lightweight custom models"]}
{"product_name":"Cloud TPU","entity_type":"Compute \/ Infrastructure","ui":["Google Cloud Console","gcloud CLI","REST API","Client Libraries"],"connected_to":["Compute Engine","Google Kubernetes Engine (GKE)","Vertex AI","Cloud Storage","VPC Network"],"short_description":"Cloud TPU (Tensor Processing Unit) provides access to Google's custom-designed application-specific integrated circuits (ASICs) optimized to accelerate machine learning workloads, particularly for TensorFlow, PyTorch, and JAX.","use_cases":["Training large-scale deep learning models (e.g., LLMs, BERT, ResNet)","High-throughput batch inference","Accelerating matrix-math intensive scientific computing","Fine-tuning foundation models"],"not_used_when":["Running general-purpose computing tasks (non-ML workloads)","The workload relies heavily on custom CUDA kernels specific to NVIDIA GPUs","Training very small models where the cost of TPU overhead exceeds the performance benefit (CPU is sufficient)","Codebases that are not compatible with XLA (Accelerated Linear Algebra) compilation"]}
{"product_name":"TensorBoard","entity_type":"Managed Service","ui":["Web UI","Google Cloud Console","Python SDK","gcloud CLI","REST API"],"connected_to":["Vertex AI Training","Vertex AI Pipelines","Vertex AI Workbench","Cloud Storage","Vertex AI Experiments"],"short_description":"A fully managed, enterprise-ready version of the Open Source TensorBoard tool integrated into Vertex AI, used for tracking, visualizing, and comparing machine learning experiments without the need to manually provision storage or servers.","use_cases":["Visualizing training metrics (loss, accuracy) in real-time","Comparing the performance of different hyperparameter tuning runs","Profiling model execution to identify performance bottlenecks","Visualizing model graphs and data embeddings","Collaborating on ML experiments within a team environment"],"not_used_when":["Running simple, offline local experiments where cloud synchronization is unnecessary","Strict data residency requirements prohibit uploading training logs to the cloud","Cost minimization is the absolute priority for small-scale hobby projects (as local TensorBoard is free)","Using a machine learning framework that does not support TensorBoard logging formats"]}
{"product_name":"Cloud Data Fusion","entity_type":"Managed Service","ui":["Graphical User Interface (GUI)","REST API","gcloud CLI"],"connected_to":["Cloud Dataproc","BigQuery","Cloud Storage","Cloud Spanner","Cloud SQL","Cloud Pub\/Sub","Cloud Composer"],"short_description":"A fully managed, cloud-native data integration service based on the open-source CDAP project, providing a visual point-and-click interface for building and managing ETL\/ELT data pipelines without writing code.","use_cases":["Building code-free ETL\/ELT pipelines","Data replication from on-premises databases (Oracle, SQL Server) to BigQuery","Visual data wrangling and preparation for analytics","Aggregating data from disparate SaaS applications and databases into a Data Lake","Metadata management and lineage tracking"],"not_used_when":["Ultra-low latency, sub-second real-time stream processing is required (prefer Cloud Dataflow)","The engineering team prefers writing, versioning, and maintaining raw code (Python\/Java\/Scala) over using visual drag-and-drop tools","Handling very small, infrequent data transfers where the cost and startup time of the underlying Dataproc cluster are unjustified","Complex custom logic is required that cannot be easily represented by standard plugins or directives"]}
{"product_name":"AutoML Vision","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Web UI)","REST API","Client Libraries (Python, Java, Node.js, etc.)","gcloud CLI"],"connected_to":["Google Cloud Storage (for storing training data)","Vertex AI (AutoML is now integrated into the Vertex AI platform)","Cloud Logging","Cloud Monitoring"],"short_description":"A service that enables developers with limited machine learning expertise to train high-quality, custom image classification and object detection models using Google's state-of-the-art transfer learning and neural architecture search technology.","use_cases":["Classifying images into custom categories specific to a business domain (e.g., specific car models, real estate room types)","Detecting specific objects within images (e.g., manufacturing defects on an assembly line)","Medical imaging analysis for specific pathologies","Retail shelf analysis and product recognition","Biodiversity monitoring (identifying specific plant or animal species)"],"not_used_when":["The standard pre-trained Cloud Vision API already covers the labels or objects you need to detect","You require granular control over the model architecture, hyperparameters, and training loop (use Custom Training on Vertex AI instead)","You have an extremely small dataset that does not meet the minimum requirements for training (e.g., fewer than 10-50 images per label)","You are on a very strict budget and can utilize open-source models without managed infrastructure costs"]}
{"product_name":"Compute Engine","entity_type":"Compute \/ Infrastructure","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Client Libraries"],"connected_to":["Virtual Private Cloud (VPC)","Cloud Load Balancing","Persistent Disk","Cloud Storage","Google Kubernetes Engine (GKE)","Identity and Access Management (IAM)","Cloud Operations Suite (Monitoring & Logging)"],"short_description":"Compute Engine offers secure and customizable virtual machines (VMs) running on Google's infrastructure, allowing users to create, run, and manage virtual machines with specific hardware and operating system configurations.","use_cases":["Migrating existing on-premise applications (Lift and shift)","High-performance computing (HPC) and batch processing","Running self-managed databases (e.g., SQL Server, Oracle)","Hosting web servers and application stacks (e.g., LAMP)","Running legacy applications that require specific OS kernel modifications"],"not_used_when":["You require a fully managed serverless environment where you do not want to manage the OS (consider Cloud Run or App Engine)","You need a managed database service to avoid administrative overhead like patching and backups (consider Cloud SQL or Firestore)","You are hosting a simple static website (consider Cloud Storage or Firebase Hosting)","You want to run containers with automated orchestration without managing the underlying nodes (consider GKE Autopilot)"]}
{"product_name":"AutoML Vision Edge","entity_type":"Service Feature","ui":["Google Cloud Console","REST API","gcloud CLI","Client Libraries"],"connected_to":["Google Cloud Storage","Vertex AI","Firebase","ML Kit","Google Container Registry","Artifact Registry"],"short_description":"A machine learning service that enables the training of custom computer vision models (classification and object detection) specifically optimized for export and deployment on edge devices, mobile applications, and IoT hardware, allowing for low-latency and offline inference.","use_cases":["Real-time manufacturing defect detection on assembly lines without internet connectivity","Mobile applications requiring offline image classification","Object detection on drones, robots, or IoT devices","Smart retail inventory scanning on handheld devices"],"not_used_when":["You require the highest possible model accuracy and have guaranteed internet connectivity (use server-side AutoML Vision)","You do not have any custom training data (use the pre-trained Cloud Vision API)","You need full manual control over the neural network architecture and hyperparameters (use custom training on Vertex AI)","The target hardware is a microcontroller too small to support TensorFlow Lite"]}
{"product_name":"Cloud Storage","entity_type":"Managed Service","ui":["Web Console","Command Line Interface (gsutil\/gcloud)","REST API","Client Libraries"],"connected_to":["BigQuery","Dataflow","Cloud Functions","Compute Engine","Cloud CDN","Pub\/Sub","Dataproc","Cloud Run"],"short_description":"A scalable, highly durable, and secure object storage service designed for storing unstructured data (blobs).","use_cases":["Data lakes for analytics","Backup and disaster recovery","Static website hosting","Storing media content (images, videos)","Machine learning model and dataset storage"],"not_used_when":["You require a POSIX-compliant file system with directory hierarchy and file locking (use Filestore)","You need block storage for VM operating systems (use Persistent Disk)","You need low-latency structured data querying or ACID transactions (use Cloud SQL or Spanner)","You need real-time database capabilities (use Firestore or Bigtable)"]}
{"product_name":"Google Kubernetes Engine","entity_type":"Managed Infrastructure Platform","ui":["Google Cloud Console (Web UI)","gcloud CLI","kubectl (Command Line Interface)","REST API"],"connected_to":["Compute Engine","Artifact Registry","Container Registry","Cloud Load Balancing","Cloud Build","Cloud IAM","Cloud Monitoring","Cloud Logging","Virtual Private Cloud (VPC)","Persistent Disk"],"short_description":"A managed environment for deploying, managing, and scaling containerized applications using Kubernetes, abstracting away the management of the Kubernetes control plane.","use_cases":["Orchestrating complex microservices architectures","Running machine learning training and inference workloads","Hybrid and multi-cloud application deployments (via GKE Enterprise\/Anthos)","Stateful applications requiring persistent storage","Large-scale batch processing"],"not_used_when":["Hosting simple static websites (better suited for Cloud Storage or Firebase)","Running very small, low-traffic stateless applications where cluster management overhead is unnecessary (better suited for Cloud Run)","Deploying legacy monolithic applications that cannot be containerized (better suited for Compute Engine)","Executing simple, event-driven single functions (better suited for Cloud Functions)"]}
{"product_name":"VPC Service Controls","entity_type":"Security","ui":["Google Cloud Console","gcloud CLI","REST API","Terraform"],"connected_to":["Access Context Manager","Cloud Storage","BigQuery","Cloud SQL","Compute Engine","Google Kubernetes Engine","Cloud Pub\/Sub","Cloud Logging"],"short_description":"A security service that enables users to define security perimeters around Google Cloud resources to mitigate data exfiltration risks and control communication between services.","use_cases":["Preventing data exfiltration from managed services like Cloud Storage or BigQuery.","Isolating sensitive production environments from development or testing environments.","Enforcing context-aware access (via Access Context Manager) based on IP address, user identity, or device trust.","Securing hybrid connectivity to ensure data only moves between on-premises networks and specific VPCs."],"not_used_when":["The specific Google Cloud service required is not on the supported products list.","The administrative overhead of managing complex perimeters and ingress\/egress rules outweighs the security requirements (e.g., in low-risk sandbox environments).","Resources require unrestricted public internet access without any context-based limitations."]}
{"product_name":"Vertex AI Feature Store","entity_type":"Managed Service","ui":["Google Cloud Console","Vertex AI SDK (Python)","REST API","gcloud CLI"],"connected_to":["BigQuery","Vertex AI Pipelines","Vertex AI Training","Vertex AI Prediction","Dataflow","Cloud Storage"],"short_description":"A fully managed, centralized repository for organizing, storing, and serving machine learning features. It unifies ML data pipelines, enabling feature sharing across teams and ensuring consistency between training and inference (online\/offline skew prevention).","use_cases":["Real-time fraud detection requiring low-latency feature retrieval.","Recommendation systems needing up-to-date user history features.","Generating point-in-time correct training datasets to prevent data leakage.","Sharing and reusing engineered features across multiple data science teams."],"not_used_when":["You only need batch predictions and have no requirement for low-latency online serving (BigQuery alone is usually sufficient and cheaper).","The project is a small-scale prototype where the infrastructure overhead outweighs the benefits of a centralized store.","You are working exclusively with unstructured data (like raw images or audio) without pre-computing embeddings.","You do not need to share features across models or teams."]}
{"product_name":"TensorFlow Enterprise","entity_type":"Product","ui":["API driven","Shell commands"],"connected_to":["Vertex AI","Compute Engine","Google Kubernetes Engine (GKE)","Cloud Storage","Cloud TPU","Deep Learning VM Images"],"short_description":"A Google Cloud-optimized distribution of TensorFlow that offers enterprise-grade support, performance optimizations for GCP hardware, and Long Term Support (LTS) for specific versions.","use_cases":["Mission-critical production machine learning pipelines requiring stability","Training models that need security patches and bug fixes for up to 3 years (LTS)","High-performance training utilizing Cloud TPUs or NVIDIA GPUs on GCP","Large-scale distributed training on Vertex AI or GKE"],"not_used_when":["You are using a different deep learning framework like PyTorch or JAX","You require the absolute latest experimental features found only in TensorFlow nightly builds","You are running small-scale local experiments where cloud-specific optimizations provide no benefit","You do not require enterprise-level support or Service Level Agreements (SLAs)"]}
{"product_name":"Firebase Messaging","entity_type":"Managed Service","ui":["REST API","Firebase Console (Web UI)","Firebase CLI","Admin SDKs"],"connected_to":["Cloud Functions for Firebase","Google Analytics","BigQuery","Firebase Authentication","Firestore","Realtime Database"],"short_description":"A cross-platform messaging solution that allows you to reliably send messages (notifications and data payloads) to Android, iOS, and web applications at no cost.","use_cases":["Sending push notifications to drive user re-engagement","Signaling new content availability (e.g., new email or chat message)","Silent background data synchronization triggers","Topic-based messaging for news or alerts"],"not_used_when":["Streaming high-frequency real-time data (use WebSockets or Cloud Pub\/Sub instead)","Sending data payloads larger than 4KB","Strict First-In-First-Out (FIFO) message ordering is critical","Guaranteed immediate delivery is required (FCM is 'best effort' and subject to device power management constraints)"]}
{"product_name":"AutoML Video Intelligence","entity_type":"Machine Learning Service","ui":["Google Cloud Console (integrated into Vertex AI)","REST API","Command Line Interface (gcloud)","Client Libraries (Python, Java, Node.js, Go)"],"connected_to":["Google Cloud Storage (for storing video datasets and training data)","Vertex AI (platform for managing the ML lifecycle)","Video Intelligence API (for pre-trained model capabilities)"],"short_description":"A service that enables developers to train high-quality custom machine learning models to classify videos, detect objects, and track objects using their own labeled video datasets, without requiring deep expertise in model architecture.","use_cases":["Categorizing video content based on custom labels (e.g., specific sports actions like 'goal' or 'foul').","Tracking custom objects across video frames (e.g., tracking a specific brand logo in broadcast footage).","Industrial quality control (e.g., identifying specific defects in manufacturing line videos).","Behavioral analysis in research (e.g., identifying specific animal behaviors in wild footage)."],"not_used_when":["The standard pre-trained Video Intelligence API can already detect the objects or labels needed (e.g., generic 'dog', 'car', 'person').","You require full manual control over the neural network architecture and hyperparameters (use custom training on Vertex AI instead).","You have insufficient training data to produce a statistically significant model.","Ultra-low latency real-time processing is the primary constraint (AutoML models are often optimized for accuracy over speed compared to lightweight edge models)."]}
{"product_name":"LIT","entity_type":"Library \/ SDK","ui":["Web-based GUI","Python API","Command Line Interface"],"connected_to":["Vertex AI","TensorFlow","PyTorch","Google Colab","Hugging Face Transformers"],"short_description":"The Learning Interpretability Tool (LIT) is a visual, interactive platform designed for understanding, debugging, and visualizing the behavior of machine learning models, particularly for NLP and image data.","use_cases":["Debugging model errors and analyzing failure modes","Detecting bias and fairness issues in models","Generating counterfactuals to test model robustness","Comparing two models side-by-side"],"not_used_when":["Automated, headless production monitoring is required","Serving models for high-throughput real-time inference","Analyzing massive datasets without sampling (due to browser\/local memory constraints)"]}
{"product_name":"Dialogflow","entity_type":"Managed Service","ui":["Web Console (Dialogflow ES & CX)","REST API","gRPC API","Client Libraries (SDKs)","gcloud CLI"],"connected_to":["Cloud Functions","App Engine","Cloud Run","BigQuery","Vertex AI","Cloud Speech-to-Text","Cloud Text-to-Speech","Cloud Logging"],"short_description":"A natural language understanding (NLU) platform used to design and integrate conversational user interfaces (chatbots and voicebots) into mobile apps, web applications, devices, and interactive voice response systems.","use_cases":["Customer support chatbots","Interactive Voice Response (IVR) for call centers","FAQ automation","Commerce and booking agents","Voice interfaces for IoT devices"],"not_used_when":["You require strictly offline, on-device processing with no internet connection","You only need simple regex or keyword-based command parsing without complex intent classification","You require full control over the underlying ML model architecture and training pipeline (custom models on Vertex AI are better suited for this)","You are building a purely unstructured generative text application without specific business logic flows (raw LLMs via Vertex AI may be simpler)"]}
{"product_name":"Vertex AI Prediction","entity_type":"Managed Service","ui":["Google Cloud Console","REST API","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","AI Platform Training","Cloud Logging","Cloud Monitoring","Vertex AI"],"short_description":"A legacy managed service used to host trained machine learning models in the cloud and use them to make predictions on new data (now largely superseded by Vertex AI).","use_cases":["Serving TensorFlow, scikit-learn, or XGBoost models for real-time inference","Running batch prediction jobs on large datasets stored in Cloud Storage","Hosting custom prediction routines using custom containers","Auto-scaling model serving infrastructure based on request volume"],"not_used_when":["Starting a new project (use Vertex AI Prediction instead, as AI Platform is the legacy predecessor)","You need to train a model (use AI Platform Training or Vertex AI Training)","You require ultra-low latency on-device inference (use TensorFlow Lite or Edge ML)","You are deploying simple rule-based logic that does not require an ML framework"]}
{"product_name":"Filestore","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI (Command Line)","REST API","Terraform \/ Client Libraries"],"connected_to":["Compute Engine","Google Kubernetes Engine (GKE)","Cloud Run","Google Cloud VMware Engine","VPC Network"],"short_description":"A fully managed, scalable, and high-performance network file storage service that provides access to files via the NFSv3 protocol.","use_cases":["Enterprise application migration (Lift and Shift) requiring shared filesystems","Content Management Systems (CMS) like WordPress or Drupal","Media rendering and video processing","Machine learning and data analytics workloads","Shared storage for containerized applications in GKE"],"not_used_when":["You need object storage for unstructured data accessible via HTTP (use Cloud Storage)","You require block storage for a single instance with the lowest possible latency (use Persistent Disk or Local SSD)","You need native SMB support specifically for Windows environments (consider Google Cloud NetApp Volumes)","You need extremely low-cost archival storage for data that is rarely accessed (use Cloud Storage Archive class)"]}
{"product_name":"Block Storage","entity_type":"Storage","ui":["Google Cloud Console","gcloud CLI","REST API","Terraform"],"connected_to":["Compute Engine","Google Kubernetes Engine (GKE)","VMware Engine","Backup and DR Service"],"short_description":"High-performance, durable block storage (primarily Persistent Disk and Hyperdisk) that attaches to Virtual Machines and containers, functioning like a physical hard drive or SSD.","use_cases":["Boot disks for Compute Engine instances","Database storage (e.g., self-hosted MySQL, PostgreSQL, Oracle)","Persistent volumes for stateful GKE applications","Enterprise applications requiring high IOPS and low latency","Mission-critical workloads requiring regional replication"],"not_used_when":["Storing unstructured data (images, videos, backups) meant for HTTP access (use Cloud Storage instead)","Need a fully managed Network Attached Storage (NAS) file system shared across many VMs simultaneously (use Cloud Filestore instead)","Long-term archival storage where access speed is not critical (use Cloud Storage Archive class)","Ultra-low latency temporary caching is required and data persistence is not needed (use Local SSD instead)"]}
{"product_name":"Vertex Explainable AI","entity_type":"Service Feature","ui":["Google Cloud Console","REST API","Vertex AI SDK (Python)","gcloud CLI"],"connected_to":["Vertex AI Prediction","Vertex AI AutoML","Vertex AI Custom Training","BigQuery ML","Cloud Storage","TensorFlow","XGBoost","Scikit-learn"],"short_description":"A set of capabilities within Vertex AI that helps users understand and interpret machine learning model predictions by attributing the output to specific input features (feature attribution).","use_cases":["Debugging model performance to understand why a model made a specific error","Detecting data bias and ensuring model fairness","Meeting regulatory compliance requirements for AI transparency (Right to Explanation)","Building trust with stakeholders by visualizing feature importance"],"not_used_when":["Ultra-low latency is required for the prediction response (generating explanations adds significant processing overhead)","The model is inherently interpretable (e.g., a simple linear regression or decision tree) where complex attribution methods are unnecessary","You are trying to determine real-world causality (it explains the model's logic, not necessarily the causal relationships in the physical world)"]}
{"product_name":"Vertex AI Pipelines","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","Vertex AI SDK (Python)","gcloud CLI","REST API"],"connected_to":["Cloud Storage","BigQuery","Artifact Registry","Vertex AI Training","Vertex AI Experiments","Vertex ML Metadata","Cloud Scheduler","Cloud Functions"],"short_description":"A serverless, managed orchestration service within the Vertex AI platform that allows users to automate, monitor, and govern machine learning workflows using Kubeflow Pipelines or TensorFlow Extended specifications.","use_cases":["Automating end-to-end MLOps workflows (data prep, training, evaluation, deployment)","Continuous training (CT) pipelines triggered by data changes","Batch prediction workflows","Ensuring reproducibility and lineage tracking for ML experiments"],"not_used_when":["Running simple, single-step scripts where the overhead of containerization and orchestration is unnecessary","Real-time streaming data processing is required (Dataflow is preferred)","General-purpose IT automation is needed with no ML context (Cloud Workflows or Cloud Composer are often better suited)","Ultra-low latency between steps is critical, as there is overhead in provisioning containers for each step"]}
{"product_name":"Kubeflow Pipelines","entity_type":"Machine Learning Platform","ui":["Vertex AI Console (Web UI)","Python SDK (KFP)","REST API","gcloud CLI"],"connected_to":["Vertex AI","Google Kubernetes Engine (GKE)","Cloud Storage","Artifact Registry","BigQuery","Cloud Build","Dataflow"],"short_description":"An orchestration engine for deploying and managing end-to-end machine learning workflows based on Docker containers. On GCP, it is primarily consumed as the fully managed 'Vertex AI Pipelines' service, though it can also be self-hosted on GKE.","use_cases":["Automating end-to-end MLOps workflows (ingestion, training, evaluation, deployment)","Continuous training (CT) and scheduled model retraining","Tracking metadata and lineage of ML artifacts","Batch prediction pipelines","Reproducible machine learning experiments"],"not_used_when":["Running simple, single-step scripts where orchestration infrastructure adds unnecessary complexity","Real-time streaming data processing is required (use Dataflow instead)","Sub-second latency between task transitions is required (due to container provisioning overhead)","The team does not have knowledge of containerization (Docker)"]}
{"product_name":"Bigtable","entity_type":"Database Service","ui":["Google Cloud Console (Web UI)","cbt CLI tool","gcloud CLI","REST API","gRPC API","HBase Shell (via Dataproc)"],"connected_to":["Dataflow","Dataproc","BigQuery","Cloud Pub\/Sub","Cloud Functions","Vertex AI","Cloud Monitoring"],"short_description":"A fully managed, scalable NoSQL database service designed for large analytical and operational workloads, offering high throughput and low latency at petabyte scale.","use_cases":["IoT time-series data storage","Ad Tech (Real-time bidding, user profiles)","Financial data analysis (market history, fraud detection)","Personalization and recommendation engines","Geospatial data processing"],"not_used_when":["The dataset is small (less than 1 TB) as it is not cost-effective","Complex multi-row ACID transactions are required (Bigtable only supports single-row transactions)","Complex SQL joins and ad-hoc queries are the primary access pattern (use Cloud SQL or Spanner instead)","Strict relational schemas are required"]}
{"product_name":"Cloud SQL","entity_type":"Database Service","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Cloud SQL Auth Proxy","Client Libraries"],"connected_to":["Compute Engine","Google Kubernetes Engine (GKE)","Cloud Run","App Engine","Cloud Functions","BigQuery (via Federated Queries)","Cloud Monitoring","Virtual Private Cloud (VPC)"],"short_description":"A fully managed relational database service that allows you to set up, maintain, manage, and administer MySQL, PostgreSQL, and SQL Server databases in the cloud.","use_cases":["Web frameworks and CMS (WordPress, Drupal, Django, Ruby on Rails)","E-commerce applications","CRM and ERP systems","Lift and shift of on-premise relational databases","General-purpose OLTP (Online Transaction Processing) workloads"],"not_used_when":["You require global horizontal scaling with active-active writes across regions (use Cloud Spanner instead)","You need to store unstructured or semi-structured NoSQL data (use Firestore or Cloud Bigtable instead)","You are performing petabyte-scale data warehousing and analytics (use BigQuery instead)","You require full control over the operating system or specific database engine flags not supported by the managed service (use a self-managed database on Compute Engine)"]}
{"product_name":"CDN","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI","REST API","Terraform\/IaC"],"connected_to":["Cloud Load Balancing (specifically Global External HTTP(S) Load Balancers)","Cloud Storage","Compute Engine","Cloud Run","Google Kubernetes Engine (GKE)"],"short_description":"Google Cloud CDN uses Google's globally distributed edge points of presence to cache HTTP(S) load balanced content close to users, thereby reducing latency and origin server load.","use_cases":["Serving static website assets (images, CSS, JavaScript, fonts)","Video streaming and media delivery","Large file downloads (software updates, game data)","Absorbing traffic spikes to protect backend infrastructure","Reducing egress costs and latency for global user bases"],"not_used_when":["You are not using a Global External HTTP(S) Load Balancer (it is a strict prerequisite)","Content is highly dynamic, personalized per request, and cannot be cached","The application is strictly internal\/intranet based with no need for global edge distribution","Strict data sovereignty requirements prevent data from being cached in edge locations across different borders"]}
{"product_name":"Dataprep","entity_type":"Managed Service","ui":["Web UI","REST API"],"connected_to":["Cloud Dataflow","Cloud Storage","BigQuery","Cloud Composer","Looker Studio"],"short_description":"An intelligent, serverless data service built in partnership with Trifacta (Alteryx) that allows users to visually explore, clean, and prepare data for analysis and machine learning without writing code.","use_cases":["Self-service data wrangling for business analysts","Cleaning messy raw data (CSVs, Excel, JSON) for ingestion into BigQuery","Visual data profiling and anomaly detection","Preparing datasets for Machine Learning models"],"not_used_when":["Real-time streaming data processing is required (Dataprep is batch-only)","Complex, custom coding transformations are needed that go beyond visual recipes (better suited for Cloud Dataflow\/Apache Beam)","Simple transformations can be achieved more cost-effectively via standard SQL in BigQuery","Sub-second latency is required"]}
{"product_name":"Vertex AI Model Monitoring","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","Vertex AI SDK (Python)","gcloud CLI","REST API"],"connected_to":["Vertex AI Endpoints","BigQuery","Cloud Storage","Cloud Logging","Cloud Monitoring","Vertex AI Pipelines"],"short_description":"A managed service within the Vertex AI suite that automatically tracks the performance of deployed machine learning models by analyzing input signals and output predictions to detect training-serving skew and prediction drift.","use_cases":["Detecting training-serving skew (when production data distribution differs from training data).","Identifying prediction drift (when model outputs change significantly over time).","Monitoring feature attribution to understand changes in feature importance.","Triggering automated retraining workflows via Cloud Monitoring alerts when drift thresholds are breached."],"not_used_when":["The model is hosted outside of Vertex AI and you cannot implement the required custom request\/response logging format.","You are monitoring raw unstructured data (like raw audio or video files) without converting them to embeddings first, as statistical drift detection works best on structured data or embeddings.","The cost of logging and analyzing every prediction request is prohibitive for extremely high-volume, low-value transaction models."]}
{"product_name":"Vertex AI Workbench","entity_type":"Managed Service","ui":["Web User Interface (JupyterLab)","Command Line Interface (gcloud)","Vertex AI SDK (Python)","REST API"],"connected_to":["BigQuery","Cloud Storage","Vertex AI Training","Vertex AI Pipelines","Dataproc","Dataflow","IAM"],"short_description":"A unified, managed Jupyter Notebook development environment designed for the entire data science workflow, offering deep integration with Google Cloud data and AI services.","use_cases":["Exploratory Data Analysis (EDA)","Prototyping and developing Machine Learning models","Querying and visualizing data directly from BigQuery","Collaborative data science experimentation","Preparing data for large-scale training"],"not_used_when":["Serving models for production inference (use Vertex AI Prediction)","Running large-scale, unattended, or long-duration training jobs (use Vertex AI Training)","Orchestrating complex, automated MLOps pipelines (use Vertex AI Pipelines)","Hosting general-purpose web applications or static sites"]}
{"product_name":"Vertex AI Training","entity_type":"Managed Service","ui":["Google Cloud Console","gcloud CLI","REST API","Python Client Library"],"connected_to":["Cloud Storage","BigQuery","Container Registry","Artifact Registry","AI Platform Prediction","Vertex AI"],"short_description":"A managed service that enables the training of machine learning models using Google Cloud's infrastructure, supporting frameworks like TensorFlow, PyTorch, and Scikit-learn, as well as custom containers. (Note: It is the predecessor to Vertex AI Training).","use_cases":["Training large-scale deep learning models using GPUs or TPUs","Running distributed training jobs across multiple nodes","Automated hyperparameter tuning","Training models with custom dependencies using Docker containers"],"not_used_when":["Starting a new project (Google recommends using Vertex AI Training, which is the successor)","You need a no-code solution (use Vertex AI AutoML)","The dataset is small enough to train quickly on a local machine","You require a fully unified MLOps platform with integrated feature stores and pipelines (use Vertex AI)"]}
{"product_name":"AutoML Tables","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Web UI)","REST API","Client Libraries (Python, Java, NodeJS, Go)","gcloud CLI"],"connected_to":["BigQuery","Cloud Storage","Vertex AI","AI Platform"],"short_description":"A supervised machine learning service that automatically builds, trains, and deploys models on structured data (tabular data) by handling feature engineering, model selection, and hyperparameter tuning without requiring extensive ML expertise. (Note: This functionality is now integrated into Vertex AI).","use_cases":["Fraud detection in financial transactions","Customer churn prediction","Lead conversion scoring","Inventory demand forecasting","Dynamic pricing optimization","Credit risk analysis"],"not_used_when":["Working with unstructured data like images, video, or audio (use AutoML Vision or Video Intelligence instead)","Full manual control over model architecture and hyperparameters is required (use Custom Training)","The dataset is extremely small and insufficient for training complex models","Ultra-low latency (sub-millisecond) inference is required, where a simple custom regression model might be faster","Cost is a primary constraint and the workload can be handled by simple statistical methods (e.g., linear regression in BigQuery ML)"]}
{"product_name":"Vertex AI Metadata","entity_type":"Managed Service","ui":["Google Cloud Console (Vertex AI section)","Python SDK (google-cloud-aiplatform)","REST API"],"connected_to":["Vertex AI Pipelines","Vertex AI Experiments","Vertex AI Model Registry","Google Cloud Storage","BigQuery"],"short_description":"A managed service based on ML Metadata (MLMD) that records the metadata, artifacts, and lineage of machine learning workflows to help analyze, debug, and audit the performance and creation of ML models.","use_cases":["Tracking the lineage of datasets and models to understand how an artifact was derived","Comparing parameters and metrics across different ML experiments","Auditing ML pipeline executions for governance and compliance","Visualizing the relationship between artifacts and executions in a graph format"],"not_used_when":["Storing the actual content of large files, datasets, or model binaries (store the URI\/path instead)","Acting as a general-purpose application database (SQL\/NoSQL)","High-frequency real-time application logging (use Cloud Logging instead)","Running simple, one-off scripts where reproducibility and lineage tracking are not required"]}
{"product_name":"Deep Learning VM Images","entity_type":"Product","ui":["Google Cloud Console","gcloud CLI","Compute Engine API","SSH"],"connected_to":["Compute Engine","Vertex AI Workbench","Cloud Storage","Artifact Registry"],"short_description":"A set of pre-configured Compute Engine virtual machine images optimized for data science and machine learning, coming pre-installed with popular frameworks (TensorFlow, PyTorch), NVIDIA CUDA drivers, and JupyterLab.","use_cases":["Rapid prototyping of deep learning models","Running Jupyter Notebooks on powerful cloud GPUs","Custom training jobs requiring full OS control","Data science experimentation"],"not_used_when":["You prefer a fully managed, serverless training environment (use Vertex AI Training)","You need production-grade, auto-scaling model serving (use Vertex AI Prediction)","You want to avoid managing OS-level security and updates","You are running non-ML workloads"]}
{"product_name":"Cloud Build","entity_type":"Developer Platform","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Client Libraries"],"connected_to":["Artifact Registry","Container Registry","Cloud Run","Google Kubernetes Engine (GKE)","App Engine","Cloud Functions","Cloud Storage","Secret Manager","Cloud Source Repositories","GitHub","Bitbucket","Cloud Deploy"],"short_description":"A fully managed, serverless CI\/CD platform that executes builds on Google Cloud infrastructure. It executes steps defined in a configuration file to build, test, and deploy software across various languages and environments.","use_cases":["Continuous Integration and Continuous Deployment (CI\/CD) pipelines","Building, testing, and pushing Docker container images","Automating deployments to Cloud Run, GKE, and App Engine","Executing Infrastructure as Code (IaC) workflows (e.g., Terraform, Packer)","Running automated testing suites inside containers"],"not_used_when":["Building applications specifically for Apple platforms (iOS\/macOS) as it primarily supports Linux and Windows containers","You require a persistent build server with state retained locally between builds (Cloud Build environments are ephemeral)","You need complex manual approval gates within the build logic itself (Cloud Deploy is better suited for the release management aspect)","You are operating in a strictly air-gapped on-premise environment without Anthos\/Google Distributed Cloud"]}
{"product_name":"Cloud Source Repositories","entity_type":"Managed Service","ui":["Google Cloud Console","gcloud CLI","Git CLI","REST API"],"connected_to":["Cloud Build","App Engine","Cloud Functions","Pub\/Sub","Cloud Logging","IAM"],"short_description":"A fully managed, private Git repository service hosted on Google Cloud that allows you to store, manage, and track code changes.","use_cases":["Hosting private Git repositories securely within GCP","Mirroring repositories from GitHub or Bitbucket to trigger GCP-native pipelines","Triggering CI\/CD workflows via Cloud Build based on commit events","Debugging production applications by linking source code to stack traces"],"not_used_when":["You require advanced project management features like issue tracking, wikis, or Kanban boards (use GitHub or GitLab)","You need a rich Pull Request\/Merge Request workflow with extensive code review tools (CSR features are basic)","You are hosting public open-source projects","You are looking for a complete DevOps platform rather than just storage"]}
{"product_name":"Cloud Functions","entity_type":"Serverless Compute","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Client Libraries","Terraform\/IaC"],"connected_to":["Cloud Storage","Cloud Pub\/Sub","Firestore","Cloud Scheduler","Cloud Logging","Eventarc","Secret Manager","Firebase"],"short_description":"A scalable, serverless execution environment that allows you to run single-purpose code snippets in response to events (like HTTP requests, file uploads, or database changes) without provisioning or managing servers.","use_cases":["Real-time file processing (e.g., resizing images uploaded to Cloud Storage)","Data processing pipelines (ETL) triggered by Pub\/Sub messages","Lightweight HTTP APIs and Webhooks","Serverless backends for mobile or web apps","Scheduled automation tasks (cron jobs)"],"not_used_when":["The process requires execution time exceeding 60 minutes (Gen 2) or 9 minutes (Gen 1)","The application requires heavy state management or persistent connections","You require specialized hardware like GPUs","You are deploying a complex, containerized application with many endpoints (Cloud Run is usually a better fit)","You need extremely consistent low-latency without 'cold starts' (unless using minimum instances)"]}
{"product_name":"Cloud TPU profiler","entity_type":"Observability & Monitoring","ui":["TensorBoard Web UI","Command Line Interface (CLI)","Python Client Library"],"connected_to":["Cloud TPU","Vertex AI TensorBoard","Cloud Storage","Compute Engine","TensorFlow","PyTorch","JAX"],"short_description":"A performance analysis tool integrated with TensorBoard that captures and visualizes execution traces of machine learning models on Cloud TPUs to help optimize training speed and resource utilization.","use_cases":["Identifying input pipeline bottlenecks where the TPU waits for data","Analyzing step time breakdown to optimize model architecture","Visualizing TPU core utilization and memory usage","Debugging performance regressions in ML training jobs"],"not_used_when":["Profiling workloads running exclusively on CPUs (use Cloud Profiler)","Profiling workloads running on GPUs (use TensorBoard Profiler for GPU)","Debugging functional logic errors in code (use a standard debugger)","Continuous monitoring of production inference where zero overhead is required"]}
{"product_name":"Cloud Natural Language API","entity_type":"API","ui":["REST API","gRPC","Google Cloud Console","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","BigQuery","Cloud Functions","Cloud Run","Dataflow","Vertex AI"],"short_description":"A managed service that provides natural language understanding technologies to developers, including sentiment analysis, entity analysis, entity sentiment analysis, content classification, and syntax analysis using pre-trained Google models.","use_cases":["Analyzing customer sentiment in product reviews or support tickets","Extracting entities (people, organizations, locations) from news articles","Classifying documents into predefined content categories","Detecting and redacting PII (Personally Identifiable Information)","Analyzing syntactic structure for linguistic research"],"not_used_when":["You need to transcribe audio to text (use Cloud Speech-to-Text instead)","You need to translate text between languages (use Cloud Translation API instead)","You require a highly specialized model for very specific industry jargon that the pre-trained model does not recognize (consider training a custom model via Vertex AI)","Simple string matching or Regular Expressions are sufficient for the task, as the API incurs cost and latency"]}
{"product_name":"Firebase","entity_type":"Application Platform","ui":["Firebase Console (Web UI)","Firebase CLI (Command Line Interface)","Client SDKs (Android, iOS, Web, Unity, C++, Flutter)","Admin SDKs \/ REST APIs"],"connected_to":["Google Cloud Platform (Projects share billing and IAM)","Cloud Functions","Cloud Firestore","Cloud Storage for Firebase","BigQuery","Google Analytics","Google Ads","Cloud Run"],"short_description":"A comprehensive platform developed by Google for creating mobile and web applications. It provides a suite of tools for building app infrastructure (database, auth, storage), releasing and monitoring (crashlytics, performance), and engaging users (analytics, messaging) without managing servers.","use_cases":["Rapid prototyping and development of mobile\/web apps","Real-time applications (chat apps, live dashboards, collaborative tools)","User authentication (Social login, email\/password, phone auth)","Serverless backend logic via Cloud Functions","Sending push notifications across platforms","App crash reporting and performance monitoring"],"not_used_when":["You require complex relational data modeling with heavy reliance on SQL joins (Cloud SQL is better suited)","You need full control over the underlying operating system or hardware infrastructure (use Compute Engine)","You have extremely high-frequency write operations to a single document (Firestore limitation)","You require long-running, heavy computational processes that exceed serverless timeout limits (use Cloud Run or GKE)","Strict on-premise data hosting is required (Firebase is a managed cloud service)"]}
{"product_name":"AutoML Text","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Web UI)","REST API","gcloud CLI","Client Libraries"],"connected_to":["Cloud Storage","Vertex AI","Natural Language API","AI Platform"],"short_description":"A machine learning service that enables developers with limited ML expertise to train high-quality custom models for text classification, entity extraction, and sentiment analysis using their own labeled data.","use_cases":["Categorizing customer support tickets into specific business topics","Extracting domain-specific entities (e.g., legal clauses, medical codes) from documents","Custom sentiment analysis for niche products where standard models fail"],"not_used_when":["The generic pre-trained Google Natural Language API provides sufficient accuracy","Full control over model architecture and hyperparameters is required (use custom training on Vertex AI instead)","The available training dataset is too small to produce a statistically significant model","Immediate, zero-latency on-device inference is required without cloud connectivity (unless using Edge export capabilities)"]}
{"product_name":"Data Catalog","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","gRPC API","Client Libraries (Python, Java, Node.js, Go)"],"connected_to":["BigQuery","Pub\/Sub","Cloud Storage","Dataplex","Cloud Data Loss Prevention (DLP)","Cloud IAM","Dataproc Metastore","Looker","Vertex AI"],"short_description":"A fully managed, scalable metadata management service (now part of the Dataplex suite) that enables organizations to discover, classify, and understand their data assets across Google Cloud and on-premises systems.","use_cases":["Centralized data discovery and search across BigQuery, Pub\/Sub, and GCS.","Attaching business metadata (tags) to technical assets for governance.","Automating the identification of sensitive data (PII) using Cloud DLP integration.","Managing data lineage to understand data origins and transformations.","Enforcing policy-based access control using metadata tags."],"not_used_when":["You need to perform data transformation or ETL (use Dataflow or Data Fusion instead).","You require Master Data Management (MDM) for editing and resolving actual data records.","You need real-time operational monitoring of database performance.","You are managing a very small dataset where a simple spreadsheet or wiki is sufficient for documentation."]}
{"product_name":"Vertex AI API","entity_type":"API","ui":["REST API","gRPC","Google Cloud Console","gcloud CLI","Client Libraries (Python, Java, Node.js, Go)"],"connected_to":["Cloud Storage","BigQuery","Artifact Registry","Container Registry","Cloud Logging","Cloud Monitoring","Dataflow","Identity and Access Management (IAM)"],"short_description":"The unified programmatic interface for Google Cloud's end-to-end machine learning platform, enabling developers to train, deploy, and manage ML models, as well as access and tune Generative AI foundation models like Gemini.","use_cases":["Training custom machine learning models (AutoML or Custom Training)","Deploying models to endpoints for online or batch predictions","Accessing, prompting, and tuning Generative AI models (LLMs)","Orchestrating MLOps workflows and pipelines","Hyperparameter tuning"],"not_used_when":["You need a specific, pre-trained solution for a common task (e.g., OCR, Speech-to-Text) and do not want to manage model versions or endpoints (use specific AI APIs like Vision API or Speech-to-Text API instead)","You are performing simple regression or classification on data residing strictly in BigQuery and wish to avoid data movement (use BigQuery ML instead)","You require a strictly local, offline environment with no cloud connectivity"]}
{"product_name":"App Engine","entity_type":"Serverless Compute","ui":["Google Cloud Console (Web UI)","gcloud CLI (Command Line Interface)","Admin API","IDE Plugins (IntelliJ, VS Code)"],"connected_to":["Cloud SQL","Firestore (Datastore mode)","Cloud Storage","Cloud Build","Cloud Logging","Cloud Monitoring","Cloud Tasks","Cloud Memcache"],"short_description":"A fully managed, serverless platform for developing and hosting web applications at scale. It abstracts away infrastructure management, allowing developers to focus on code while automatically handling load balancing, scaling, and health monitoring.","use_cases":["Scalable web applications and websites","Mobile application backends","RESTful APIs","Internal business applications","Rapid prototyping and MVP development"],"not_used_when":["You require full control over the underlying operating system or kernel configuration (use Compute Engine)","The application relies on persistent local file system storage (App Engine file system is ephemeral)","You need to run arbitrary containers with complex orchestration requirements (use Google Kubernetes Engine)","The workload requires specific hardware acceleration like GPUs (use Compute Engine or GKE)","You have extremely long-running background processes that exceed request timeouts (specifically for App Engine Standard environment)"]}
{"product_name":"AI Explanations","entity_type":"Service Feature","ui":["Google Cloud Console","Vertex AI API (REST\/gRPC)","Vertex AI SDK for Python","gcloud CLI"],"connected_to":["Vertex AI","AutoML","Cloud Storage","BigQuery","TensorFlow","Scikit-learn","XGBoost"],"short_description":"A set of capabilities within Vertex AI that provide feature attribution (such as Integrated Gradients or Sampled Shapley) to help users understand why a machine learning model made a specific prediction.","use_cases":["Debugging model behavior and improving performance","Detecting bias in datasets and model predictions","Providing transparency and building trust with stakeholders","Meeting regulatory compliance requirements for explainable AI"],"not_used_when":["Ultra-low latency is required for real-time predictions (generating explanations adds significant computational overhead)","Establishing causal relationships is required (attribution indicates correlation\/contribution, not causality)","The model is intrinsically interpretable (e.g., simple linear regression or shallow decision trees)","Using unsupported custom model architectures that are incompatible with standard attribution methods"]}
{"product_name":"Cloud Translation API","entity_type":"API","ui":["REST API","gRPC","Google Cloud Console","Command Line Interface (gcloud)","Client Libraries (Python, Go, Java, Node.js, etc.)"],"connected_to":["Cloud Storage","Vertex AI (AutoML)","Cloud Functions","Cloud Run","App Engine"],"short_description":"A managed service that uses Google's neural machine translation technology to dynamically translate text, HTML, and documents between thousands of language pairs, offering both pre-trained and custom model options.","use_cases":["Real-time translation of user-generated content (chat, comments, reviews)","Localization of websites and applications","Batch translation of documents (PDF, DOCX, PPTX)","Language detection for incoming data streams"],"not_used_when":["Offline translation is required (unless using the specific hybrid\/on-prem containerized version)","Zero-latency is critical (network overhead applies)","Translating highly creative, legal, or medical texts where 100% accuracy and nuance are mandatory without human post-editing"]}
{"product_name":"Cloud Logging","entity_type":"Observability & Monitoring","ui":["Google Cloud Console (Logs Explorer)","gcloud CLI","REST API","gRPC API","Client Libraries"],"connected_to":["Cloud Monitoring","BigQuery","Cloud Storage","Pub\/Sub","Error Reporting","Google Kubernetes Engine","Compute Engine","Cloud Run","Cloud Functions"],"short_description":"A fully managed, real-time log management service that allows users to store, search, analyze, monitor, and alert on log data and events from Google Cloud and other environments.","use_cases":["Troubleshooting and debugging application errors","Centralized log aggregation for multi-cloud environments","Security auditing and compliance reporting","Creating metrics from log data","Streaming logs to third-party SIEMs"],"not_used_when":["You need a primary database for application state (use Cloud SQL or Firestore)","You require complex SQL analytics on historical data without sinking to BigQuery","You are collecting high-frequency numerical time-series data (use Cloud Monitoring directly)","Cost is a primary constraint and high-volume debug logs are ingested without exclusion filters"]}
{"product_name":"Google Cloud\u2019s Data Labelling Service","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","REST API","gcloud CLI"],"connected_to":["Cloud Storage","Vertex AI","AutoML","BigQuery"],"short_description":"A managed service that allows developers to generate highly accurate labels for their datasets (images, video, text, and audio) by employing human labelers to annotate data for machine learning model training.","use_cases":["Drawing bounding boxes for object detection in images","Classifying text for sentiment analysis or entity extraction","Labeling video frames for object tracking","Transcribing audio for speech-to-text model training","Improving the quality of existing datasets through human review"],"not_used_when":["You require real-time or synchronous labeling (the process is asynchronous and takes time)","Data privacy or compliance regulations strictly prohibit sharing data with external human annotators (even with NDAs)","You are starting a new project (Google now recommends using Vertex AI Data Labeling instead of the standalone legacy Data Labeling Service)","The dataset is trivial in size and can be labeled internally by the developer faster than setting up a job"]}
{"product_name":"AutoML Object Detection","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Vertex AI UI)","REST API","gcloud CLI","Client Libraries (Python, Java, Node.js, Go)"],"connected_to":["Vertex AI","Cloud Storage","Cloud Vision API","Cloud Logging","Artifact Registry"],"short_description":"A service within the Vertex AI suite that enables developers to train high-quality, custom machine learning models to detect, label, and locate specific objects within images without requiring deep expertise in neural network architectures or coding.","use_cases":["Manufacturing quality control (detecting specific defects on an assembly line)","Retail inventory management (identifying specific products on shelves)","Medical imaging analysis (locating anomalies in X-rays)","Agricultural monitoring (detecting pests or crop diseases)","Worker safety monitoring (detecting specific safety gear like helmets or vests)"],"not_used_when":["Generic object detection is sufficient (e.g., detecting 'cats' or 'cars' generally) - use the pre-trained Cloud Vision API instead","You require full control over the model architecture, layers, and hyperparameters - use Vertex AI Custom Training","You have no labeled training data available","You require an on-premise solution without any cloud connectivity (unless exporting the Edge model)"]}
{"product_name":"Vertex AI Endpoints","entity_type":"Managed Service","ui":["Google Cloud Console","gcloud CLI","REST API","Vertex AI SDK (Python\/Java)"],"connected_to":["Vertex AI Model Registry","Artifact Registry","Cloud Storage","Cloud Logging","Cloud Monitoring","Virtual Private Cloud (VPC)"],"short_description":"A managed resource within Vertex AI designed to deploy machine learning models for online, real-time serving, providing low-latency predictions, autoscaling, and traffic splitting capabilities.","use_cases":["Real-time fraud detection","Online product recommendations","Serving Generative AI\/LLM responses","A\/B testing model versions via traffic splitting","High-throughput online inference"],"not_used_when":["Processing massive datasets asynchronously (use Vertex AI Batch Predictions instead)","Immediate latency is not a concern","The workload is extremely sporadic and cost is the primary concern (unless using specific serverless configurations)","Simple data transformation is required without ML inference"]}
{"product_name":"Cloud Monitoring","entity_type":"Observability & Monitoring","ui":["Google Cloud Console (Web UI)","Cloud Monitoring API","gcloud CLI","Terraform (IaC)"],"connected_to":["Cloud Logging","Compute Engine","Google Kubernetes Engine (GKE)","Cloud Run","Cloud Functions","Pub\/Sub","BigQuery","PagerDuty","Slack"],"short_description":"A fully managed service that collects metrics, events, and metadata from Google Cloud services, hosted uptime probes, and application instrumentation to provide visibility into the performance, uptime, and overall health of cloud applications.","use_cases":["Visualizing infrastructure health via dashboards (CPU, Memory, Network I\/O)","Configuring alerting policies for system failures or threshold breaches","Monitoring Service Level Objectives (SLOs) and Error Budgets","Running uptime checks for public-facing web applications","Ingesting and analyzing custom metrics from applications"],"not_used_when":["You primarily need to analyze text logs (use Cloud Logging)","You need distributed request tracing across microservices (use Cloud Trace)","You need to profile code CPU\/Memory usage at the function level (use Cloud Profiler)","You require raw metric data retention significantly longer than the default retention periods (e.g., > 6 weeks) without exporting to BigQuery"]}
{"product_name":"Identity and Access Management (IAM)","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI","REST API","Client Libraries"],"connected_to":["Compute Engine","Cloud Storage","BigQuery","Google Kubernetes Engine","Cloud Functions","Cloud Run","Virtually all Google Cloud Services"],"short_description":"A centralized service that lets you define who (identities) has what access (roles) for which specific resources across the Google Cloud Platform.","use_cases":["Granting granular permissions to users and groups for specific GCP resources","Creating and managing Service Accounts for application-to-application authentication","Enforcing the principle of least privilege across an organization","Auditing access policies and compliance"],"not_used_when":["Managing authentication and identity for end-users of your custom web or mobile applications (use Identity Platform or Firebase Auth instead)","Implementing fine-grained, application-layer business logic authorization (e.g., determining if a user can edit a specific document inside your custom CMS)","You rely solely on Primitive roles (Owner, Editor, Viewer) for production environments (best practice dictates using Predefined or Custom roles)"]}
{"product_name":"Virtual Private Cloud","entity_type":"Networking","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Terraform\/IaC"],"connected_to":["Compute Engine","Google Kubernetes Engine (GKE)","Cloud SQL","Cloud Load Balancing","Cloud VPN","Cloud Interconnect","Cloud Run (via VPC Connector)","App Engine (Flexible)"],"short_description":"A comprehensive, global virtual network implementation that is logically isolated within Google's public cloud. It provides networking functionality for Compute Engine VM instances, GKE clusters, and serverless workloads, allowing users to configure IP ranges, subnets, firewalls, and routes.","use_cases":["Isolating cloud resources in a secure private network","Creating hybrid cloud architectures by connecting to on-premises networks via VPN or Interconnect","Hosting multi-tier web applications with distinct subnets for web, application, and database layers","Managing internal traffic flow and security policies between virtual machines"],"not_used_when":["You require traditional Layer 2 networking features like broadcast or multicast (GCP VPC is a Layer 3 Software Defined Network)","You need support for non-IP protocols (e.g., raw ethernet frames)","You are deploying simple, purely public-facing static content (e.g., via Firebase or Cloud Storage) where private networking adds unnecessary complexity"]}
{"product_name":"Artifact Registry","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI","REST API","Standard Package Clients (Docker, npm, pip, Maven, Gradle, NuGet, etc.)"],"connected_to":["Cloud Build","Google Kubernetes Engine (GKE)","Cloud Run","Compute Engine","Binary Authorization","Cloud Deploy","Identity and Access Management (IAM)","Artifact Analysis"],"short_description":"A fully managed service for storing, managing, and securing container images and language packages. It is the successor to Container Registry, offering support for Docker images as well as Maven, npm, Python, Apt, Yum, and Go modules.","use_cases":["Storing and managing private Docker container images for deployment to GKE or Cloud Run","Hosting private repositories for language-specific packages (Java, Node.js, Python) to share code across teams","Integrating with CI\/CD pipelines to store build artifacts","Scanning container images for security vulnerabilities (via Artifact Analysis)","Enforcing deployment policies using Binary Authorization"],"not_used_when":["Storing raw source code (use Cloud Source Repositories, GitHub, or GitLab)","Storing unstructured object data, media files, or backups (use Cloud Storage)","You need a database for high-frequency transactional data (use Cloud SQL or Firestore)","You require a strictly public, community-hub style registry without any GCP project association (though public access is possible, Docker Hub is more common for generic open-source distribution)"]}
{"product_name":"Vertex AI Model Registry","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","Vertex AI API (REST\/gRPC)","Vertex AI SDK (Python)","gcloud CLI"],"connected_to":["Vertex AI Training","Vertex AI Prediction","Vertex AI Pipelines","Cloud Storage","Vertex AI Experiments","Artifact Registry"],"short_description":"A central repository designed to manage the lifecycle of ML models, allowing users to version, track, and deploy models to production endpoints.","use_cases":["Centralized model governance and version control","Tracking model lineage and associated metadata","Seamless deployment of models to Vertex AI Prediction endpoints","Comparing performance metrics across different model versions","Handing off models from data science teams to MLOps engineers"],"not_used_when":["Storing raw source code (use a Git repository like GitHub or Cloud Source Repositories)","Storing large training datasets (use Cloud Storage or BigQuery)","Managing general-purpose container images not related to ML inference (use Artifact Registry)","Conducting rapid, throwaway local prototyping where lifecycle management adds unnecessary overhead"]}
{"product_name":"Private Service Access","entity_type":"Networking","ui":["Google Cloud Console","gcloud CLI","Service Networking API","Terraform"],"connected_to":["VPC Network","Cloud SQL","Cloud Memorystore","Cloud Filestore","AlloyDB","Vertex AI","Cloud Build","Apigee"],"short_description":"A private connection implemented via VPC Network Peering that allows VM instances in a VPC network to communicate with supported Google and third-party services using internal IP addresses.","use_cases":["Connecting applications to Cloud SQL instances without assigning them public IP addresses","Accessing Cloud Memorystore (Redis\/Memcached) securely from a VPC","Establishing connectivity for Cloud Build private pools","Connecting to managed services like AlloyDB or Vertex AI via private network infrastructure"],"not_used_when":["Accessing public Google APIs like Cloud Storage or BigQuery (use Private Google Access instead)","Transitive peering is required (e.g., trying to access the managed service from a VPC that is peered to the VPC connected to the service)","There are overlapping IP CIDR ranges between the user VPC and the service producer network","The target service does not support the Service Networking API"]}
{"product_name":"Fairness Indicators","entity_type":"Library \/ SDK","ui":["Python API","TensorBoard Dashboard","Jupyter Notebook Widget","Vertex AI Console"],"connected_to":["Vertex AI","TensorFlow Extended (TFX)","TensorBoard","What-If Tool","Google Cloud Storage"],"short_description":"A suite of tools built on top of TensorFlow Model Analysis that enables computation and visualization of fairness metrics for binary and multiclass classification models to detect bias across different data slices.","use_cases":["Evaluating model performance across distinct demographic subgroups","Detecting algorithmic bias in classification models","Comparing multiple models for fairness prior to deployment","Debugging model failures for specific data slices"],"not_used_when":["The model task is not classification (e.g., complex generative tasks without defined fairness metrics)","There is no labeled ground truth data available for evaluation","The dataset does not contain sensitive attributes or metadata required for slicing"]}
{"product_name":"Cloud Key Management Service","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","gRPC API","Client Libraries"],"connected_to":["Cloud Storage","Compute Engine","BigQuery","Cloud SQL","Secret Manager","Google Kubernetes Engine (GKE)","Dataflow","Pub\/Sub","Identity and Access Management (IAM)"],"short_description":"A cloud-hosted key management service that allows you to manage cryptographic keys for your cloud services. It enables the generation, use, rotation, and destruction of symmetric and asymmetric cryptographic keys.","use_cases":["Implementing Customer-Managed Encryption Keys (CMEK) to encrypt data in other GCP services (like GCS buckets or SQL databases).","Encrypting Data Encryption Keys (DEKs) for envelope encryption patterns.","Creating digital signatures for data verification.","Managing keys for regulatory compliance and automatic rotation."],"not_used_when":["Storing the actual text of passwords, API keys, or certificates (use Secret Manager for storage).","Encrypting large datasets directly (KMS has size limits; use Envelope Encryption instead).","Zero-latency requirements exist (network calls to KMS introduce slight latency compared to local encryption)."]}
{"product_name":"Looker Studio","entity_type":"Analytics Service","ui":["Web UI","API"],"connected_to":["BigQuery","Google Sheets","Google Analytics","Cloud SQL","Google Ads","Cloud Storage","Spanner"],"short_description":"A fully managed, self-service business intelligence and data visualization platform (formerly Google Data Studio) that allows users to create interactive dashboards and reports from various data sources without writing code.","use_cases":["Visualizing marketing performance data from Google Ads and Analytics","Creating shareable, interactive dashboards for internal or external stakeholders","Ad-hoc reporting on data stored in BigQuery or Google Sheets","Tracking business KPIs and metrics across multiple data sources"],"not_used_when":["Complex semantic data modeling and centralized governance are required (Looker Enterprise is better suited)","Heavy data transformation or ETL is needed within the visualization layer (should be done upstream)","Advanced version control (Git integration) and CI\/CD workflows for dashboard development are necessary","Real-time monitoring requiring sub-second latency is critical"]}
{"product_name":"Cloud Run","entity_type":"Serverless Compute","ui":["Google Cloud Console (Web UI)","gcloud CLI","REST API","Client Libraries","Terraform"],"connected_to":["Artifact Registry","Cloud Build","Cloud SQL","Pub\/Sub","Eventarc","Secret Manager","Cloud Load Balancing","Cloud Storage","VPC Network"],"short_description":"A fully managed compute platform that automatically scales containerized applications. It abstracts away infrastructure management, allowing you to run stateless containers that are invocable via HTTP requests or events.","use_cases":["REST API backends and Microservices","Dynamic web applications","Event-driven data processing","Scheduled jobs and batch tasks","Asynchronous background processing"],"not_used_when":["The application requires persistent local storage (stateful workloads)","The workload requires specific hardware acceleration like GPUs (unless using specific preview features)","The process requires execution times longer than the maximum timeout limits (e.g., >60 minutes)","The application requires deep kernel-level modifications or access"]}
{"product_name":"Google Maps Platform","entity_type":"Platform","ui":["API (REST)","Client-side SDKs (JavaScript, Android, iOS)","Google Cloud Console (for management and billing)"],"connected_to":["Google Cloud Billing","BigQuery (Geospatial analytics)","Firebase","App Engine","Cloud Functions"],"short_description":"A collection of APIs and SDKs that allows developers to embed maps, visualize geospatial data, and retrieve information about places, routes, and traffic.","use_cases":["Ride-sharing and delivery tracking applications","Store locators and real estate visualization","Address autocomplete and validation for e-commerce","Logistics and route optimization","Geocoding (converting addresses to coordinates)"],"not_used_when":["The application requires full offline capabilities without periodic connectivity (caching is limited by Terms of Service)","The project has a zero-budget requirement with high volume usage (costs scale with usage)","Open-source data ownership is required (e.g., OpenStreetMap preference)","Simple static visualization is needed where a generated image would suffice without API overhead"]}
{"product_name":"Dataproc","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI (Shell)","REST API","Client Libraries (Python, Java, Go, etc.)","Component Web Interfaces (JupyterLab, Zeppelin, YARN UI, Spark History Server)"],"connected_to":["Cloud Storage (GCS)","BigQuery","Cloud Bigtable","Pub\/Sub","Cloud Logging","Cloud Monitoring","Dataproc Metastore"],"short_description":"A fully managed and highly scalable service for running Apache Spark, Apache Hadoop, Apache Flink, Presto, and over 30 other open-source tools and frameworks.","use_cases":["Migrating existing on-premise Hadoop\/Spark clusters to the cloud (Lift and Shift)","Large-scale batch processing and ETL (Extract, Transform, Load)","Machine Learning model training using Spark MLlib","Interactive data science and exploration via managed Jupyter notebooks"],"not_used_when":["You need a serverless, SQL-first enterprise data warehouse (use BigQuery instead)","You require a fully serverless streaming pipeline without managing cluster configurations or open-source versions (use Dataflow instead)","You are processing very small, sporadic, event-driven datasets where cluster startup time is inefficient (use Cloud Functions or Cloud Run)"]}
{"product_name":"Error Reporting","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","REST API","gRPC API","Client Libraries"],"connected_to":["Cloud Logging","Cloud Monitoring","App Engine","Cloud Functions","Cloud Run","Google Kubernetes Engine (GKE)","Compute Engine"],"short_description":"A managed service that counts, analyzes, and aggregates crashes in running cloud services. It groups errors to help developers identify new and recurring issues and links stack traces to source code.","use_cases":["Real-time monitoring of application crashes and exceptions","Grouping similar stack traces to reduce noise","Alerting developers when a new type of error occurs","Linking stack traces directly to specific lines in source repositories"],"not_used_when":["You need to store general informational or debug logs (use Cloud Logging instead)","You are looking for performance bottlenecks or latency issues (use Cloud Trace or Profiler)","You need to audit administrative actions or access logs (use Cloud Audit Logs)","You are trying to debug logic errors that do not result in a crash or exception"]}
{"product_name":"Cloud Scheduler","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI","REST API","Client Libraries","Terraform\/IaC"],"connected_to":["Cloud Pub\/Sub","Cloud Functions","Cloud Run","App Engine","Cloud Workflows","Arbitrary HTTP\/S Endpoints"],"short_description":"A fully managed enterprise-grade cron job scheduler that allows you to schedule units of work to be executed at defined times or regular intervals using Unix cron format.","use_cases":["Triggering periodic database backups","Invoking Cloud Functions for daily report generation","Scheduling batch processing jobs via Pub\/Sub","Keeping App Engine or Cloud Run instances warm (preventing cold starts)","Orchestrating recurring infrastructure maintenance tasks"],"not_used_when":["You require complex workflow orchestration with dependencies and conditional logic (use Cloud Workflows or Cloud Composer)","You need to schedule millions of dynamic, unique one-off tasks (use Cloud Tasks)","You require sub-minute scheduling frequency (Cloud Scheduler minimum interval is 1 minute)","The execution is triggered by an event rather than a specific time (use Eventarc or Pub\/Sub)"]}
{"product_name":"Cloud Composer","entity_type":"Managed Service","ui":["Google Cloud Console","Apache Airflow Web UI","gcloud CLI","REST API","Terraform"],"connected_to":["BigQuery","Cloud Storage","Dataflow","Dataproc","Google Kubernetes Engine","Cloud Functions","Cloud Monitoring","Pub\/Sub"],"short_description":"A fully managed workflow orchestration service built on Apache Airflow that allows you to author, schedule, and monitor pipelines that span across clouds and on-premises data centers.","use_cases":["Complex ETL\/ELT data pipelines","Orchestrating Machine Learning workflows","Data warehousing maintenance and synchronization","Multi-cloud data movement"],"not_used_when":["Real-time streaming data processing is required (use Dataflow)","Simple, standalone cron jobs are needed without dependencies (use Cloud Scheduler)","Low-latency, sub-second event responses are required (use Cloud Functions or Eventarc)","Heavy data processing is performed directly on the Airflow workers (Airflow is an orchestrator, not a compute engine)"]}
{"product_name":"Google Cloud Data Fusion","entity_type":"Data Integration Service","ui":["Graphical User Interface (Visual Pipeline Studio & Wrangler)","REST API","gcloud CLI"],"connected_to":["Cloud Dataproc","BigQuery","Cloud Storage","Cloud Spanner","Cloud Pub\/Sub","Cloud SQL","On-premises databases","SaaS applications (Salesforce, etc.)"],"short_description":"A fully managed, cloud-native data integration service based on the open-source CDAP project that allows users to visually build, manage, and monitor ETL\/ELT data pipelines without writing code.","use_cases":["Building code-free ETL\/ELT pipelines","Data wrangling and preparation for analytics","Migrating data from on-premises legacy systems to the cloud","Aggregating data from disparate sources into a data warehouse","Tracking data lineage and metadata management"],"not_used_when":["Sub-second, low-latency real-time streaming is required (Google Cloud Dataflow is better suited)","The workload is extremely small or simple (the overhead and cost of spinning up the underlying Dataproc clusters may be inefficient)","Developers prefer a pure code-first approach over a visual interface","Instant pipeline execution is required (cluster provisioning introduces startup latency)"]}
{"product_name":"Cloud Audit Logs","entity_type":"Observability & Monitoring","ui":["Google Cloud Console (Logs Explorer)","Cloud Logging API","gcloud CLI"],"connected_to":["Cloud Logging","BigQuery","Cloud Storage","Pub\/Sub","IAM","Security Command Center"],"short_description":"A fully managed service that records administrative activities, data accesses, and system events across Google Cloud resources to provide an audit trail of 'who did what, where, and when'.","use_cases":["Security auditing and forensic analysis","Regulatory compliance reporting (SOC2, HIPAA, PCI)","Tracking configuration changes and resource modifications","Monitoring data access patterns for sensitive resources"],"not_used_when":["Logging general application debug, info, or error messages (use standard Cloud Logging)","Real-time application performance profiling (use Cloud Trace or Profiler)","Storing high-volume data plane operations without cost analysis (Data Access logs can be voluminous and expensive)"]}
{"product_name":"Vertex AI SDK","entity_type":"Library \/ SDK","ui":["Code (Python)","API driven","Jupyter Notebooks","CLI (via gcloud wrapper)"],"connected_to":["Vertex AI Platform","Cloud Storage","BigQuery","Artifact Registry","Vertex AI Pipelines","Vertex AI Feature Store","Gemini API"],"short_description":"A comprehensive Python client library that enables developers to automate, manage, and execute the entire machine learning workflow and generative AI tasks on Google Cloud's Vertex AI platform.","use_cases":["Programmatically training custom ML models using cloud compute resources","Deploying models to endpoints for online or batch predictions","Building and orchestrating end-to-end MLOps pipelines","Integrating Generative AI (LLMs like Gemini) into applications","Managing model experiments, metadata, and feature stores"],"not_used_when":["The user requires a purely no-code, visual interface (use the Google Cloud Console UI instead)","The project is entirely local and requires no cloud compute or storage resources","Direct REST API or gRPC calls are preferred for lightweight integrations in languages not supported by the SDK"]}
{"product_name":"Container Registry","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","gcloud CLI","Docker CLI","REST API"],"connected_to":["Google Kubernetes Engine (GKE)","Cloud Run","Cloud Build","App Engine","Cloud Storage","Binary Authorization","Artifact Registry"],"short_description":"A legacy private container image registry that runs on Google Cloud, allowing users to store, manage, and secure Docker container images backed by Cloud Storage.","use_cases":["Storing private Docker container images for legacy projects","Deploying container images to GKE, Cloud Run, and App Engine","Integrating with CI\/CD pipelines to push build artifacts","Performing vulnerability scanning on stored images"],"not_used_when":["Starting a new project (Google strongly recommends using Artifact Registry, the successor to Container Registry)","You need to store non-container artifacts (like Maven, npm, Python, or Apt packages)","You require granular IAM access control at the repository level (Container Registry only supports bucket-level access)","You need data residency in specific regions not supported by the standard GCR multi-regions"]}
{"product_name":"Reduction Server","entity_type":"Service Feature","ui":["API","CLI (gcloud)","Python SDK"],"connected_to":["Vertex AI","Compute Engine","TensorFlow","PyTorch","Container Registry\/Artifact Registry"],"short_description":"A high-performance, all-reduce algorithm implementation optimized for Google Cloud's network infrastructure, designed to reduce latency and maximize throughput during distributed training gradient synchronization across multiple nodes.","use_cases":["Distributed training of massive machine learning models (e.g., BERT, ResNet-50) across multiple GPU nodes","Scenarios where network bandwidth is the primary bottleneck during gradient updates","Replacing standard NCCL ring-reduce patterns to leverage Google's specific network topology"],"not_used_when":["Training on a single node (no cross-node synchronization required)","Training small models where computation is the bottleneck rather than network communication","Using TPUs (which utilize their own specialized high-speed interconnects)","Using a Parameter Server training strategy instead of an All-Reduce strategy"]}
{"product_name":"RunInference API","entity_type":"Library \/ SDK","ui":["Code (Python\/Java SDK)","Dataflow Monitoring UI (for execution visualization)"],"connected_to":["Google Cloud Dataflow","Vertex AI","Google Cloud Storage","BigQuery","Pub\/Sub"],"short_description":"A high-level API and transform within the Apache Beam SDK (optimized for Google Cloud Dataflow) that streamlines machine learning inference in batch and streaming pipelines by automatically handling model loading, caching, and request batching.","use_cases":["Large-scale batch inference on datasets stored in BigQuery or GCS","Streaming inference on real-time data ingestion from Pub\/Sub","Integrating PyTorch, TensorFlow, or Scikit-learn models directly into ETL pipelines","Utilizing GPUs for inference within a distributed data processing job"],"not_used_when":["Ultra-low latency, single-request online prediction is required (use Vertex AI Endpoints instead)","You are not using a distributed data processing framework like Dataflow","The model is extremely lightweight and does not require batching or hardware acceleration"]}
{"product_name":"Natural Language API","entity_type":"ML SaaS","ui":["REST API","gRPC","Google Cloud Console","Client Libraries","gcloud CLI"],"connected_to":["Cloud Storage","BigQuery","Cloud Functions","Dataflow","Vertex AI"],"short_description":"A pre-trained machine learning service that reveals the structure and meaning of text by providing powerful natural language understanding models including sentiment analysis, entity analysis, and content classification.","use_cases":["Sentiment analysis of customer reviews and social media","Extracting entities (people, places, events) from news articles","Classifying content into predefined categories","Analyzing syntax and structure of text","Entity sentiment analysis"],"not_used_when":["You require a custom model trained on very specific domain jargon (use Vertex AI AutoML Natural Language)","You are building a conversational interface or chatbot (use Dialogflow)","You only need simple keyword matching or regex (overkill and higher cost)","Strict data residency requirements prevent sending text to public cloud endpoints (unless using specific enterprise controls)"]}
{"product_name":"AutoML Edge","entity_type":"Service Feature","ui":["Google Cloud Console (Vertex AI section)","Vertex AI API (REST\/gRPC)","gcloud CLI","Vertex AI Client Libraries (Python, Java, Node.js)"],"connected_to":["Google Cloud Storage","TensorFlow Lite","TensorFlow.js","Core ML","Google Coral \/ Edge TPU","Container Registry","Artifact Registry"],"short_description":"A capability within Vertex AI that automates the creation and training of machine learning models (specifically for vision and video) that are optimized for export and deployment on edge devices, mobile applications, and local sensors, rather than running in the cloud.","use_cases":["Mobile applications requiring offline image classification or object detection","IoT devices performing local inference for smart home security","Manufacturing assembly lines requiring low-latency visual quality control","Augmented Reality (AR) experiences requiring real-time tracking on-device","Privacy-sensitive applications where data must be processed locally without uploading to the cloud"],"not_used_when":["The highest possible model accuracy is required and latency\/internet connectivity is not an issue (Cloud-based models are generally more accurate)","You require a highly customized model architecture not supported by the AutoML presets","You are performing large-scale batch processing where cloud scaling is more efficient than edge processing","The target hardware is too constrained to run even optimized TensorFlow Lite models"]}
{"product_name":"Tabular Workflow","entity_type":"Service Feature","ui":["Google Cloud Console","Vertex AI SDK (Python)","REST API","gcloud CLI"],"connected_to":["Vertex AI","BigQuery","Cloud Storage","Vertex AI Pipelines","Dataflow"],"short_description":"A suite of managed, end-to-end machine learning pipelines within Vertex AI specifically designed to train, tune, and deploy models for tabular data tasks like classification, regression, and forecasting without writing custom pipeline code.","use_cases":["Training AutoML models for classification or regression on structured data","Training complex deep learning architectures (like TabNet or Wide & Deep) on tabular data","Large-scale time-series forecasting","Automated hyperparameter tuning and model evaluation for tabular datasets"],"not_used_when":["Working with unstructured data types like images, video, or audio","You require a highly customized model architecture not supported by the pre-built managed pipeline templates","The dataset is extremely small and simple, making the overhead of a full managed pipeline unnecessary","Real-time, online learning (updating the model with every single new data point in real-time) is required"]}
{"product_name":"TabNet","entity_type":"Service Feature","ui":["Vertex AI Console (Web UI)","Vertex AI SDK (Python)","Vertex AI API (REST)","gcloud CLI"],"connected_to":["Vertex AI","BigQuery","Cloud Storage","Vertex AI Pipelines"],"short_description":"TabNet is a deep learning architecture designed specifically for tabular data that uses sequential attention to select features at each decision step. It combines the interpretability of decision trees with the representation learning capabilities of neural networks and is offered as a managed, built-in training algorithm within Google Cloud Vertex AI.","use_cases":["Complex classification or regression tasks on structured (tabular) data","Fraud detection","Financial forecasting and risk analysis","Scenarios requiring model interpretability (feature selection\/importance)","Large-scale tabular datasets where deep learning may outperform gradient boosting"],"not_used_when":["Working with unstructured data (images, audio, video, free text)","The dataset is very small (Gradient Boosted Decision Trees like XGBoost often perform better or are more efficient on tiny datasets)","Training speed and low compute cost are the absolute highest priorities (TabNet is computationally more intensive than tree-based methods)","Simple baseline models provide sufficient accuracy"]}
{"product_name":"Vertex AI Experiments","entity_type":"Product","ui":["Google Cloud Console (Web UI)","Vertex AI SDK (Python)","REST API"],"connected_to":["Vertex AI Pipelines","Vertex AI Training","Vertex AI TensorBoard","Cloud Storage","Vertex AI Model Registry","BigQuery"],"short_description":"A managed service within the Vertex AI platform that enables data scientists to track, analyze, and compare machine learning experiment runs, logging parameters, metrics, and artifacts to establish lineage.","use_cases":["Tracking hyperparameters and metrics across multiple training runs to identify the best model","Visualizing experiment lineage to trace data sources and artifacts","Comparing different model architectures","Integrating with Vertex AI Pipelines for automated run tracking"],"not_used_when":["Monitoring live production models for prediction drift (use Vertex AI Model Monitoring instead)","General application logging or infrastructure monitoring (use Cloud Logging\/Monitoring)","You require a strictly offline, local-only experiment tracker without cloud synchronization"]}
{"product_name":"Google Cloud Pipeline Components","entity_type":"Library \/ SDK","ui":["Python SDK","Vertex AI Console (for visualization)"],"connected_to":["Vertex AI Pipelines","Vertex AI","BigQuery","Dataflow","Dataproc","Cloud Storage"],"short_description":"A Python library providing pre-built pipeline components that allow developers to interact with various Google Cloud services (like BigQuery, Dataflow, and AutoML) directly within Vertex AI Pipelines without writing custom container code.","use_cases":["Orchestrating end-to-end MLOps workflows on Vertex AI","Submitting BigQuery jobs as steps in a machine learning pipeline","Launching Dataflow jobs for data preprocessing within a pipeline","Automating AutoML model training, evaluation, and deployment"],"not_used_when":["You are not using Vertex AI Pipelines (Kubeflow Pipelines) for orchestration","You need real-time online prediction (this is for batch workflow orchestration)","You are running a simple, single-step script where the overhead of a full pipeline is unjustified","You require a specific custom environment or library version not supported by the pre-built component containers (in which case you should build a Custom Component)"]}
{"product_name":"Custom Prediction Routine (CPR)","entity_type":"Library \/ SDK","ui":["Python SDK","gcloud CLI","Google Cloud Console","REST API"],"connected_to":["Vertex AI Prediction","Vertex AI Model Registry","Cloud Storage","Artifact Registry","Container Registry"],"short_description":"A capability within the Vertex AI SDK that allows developers to build custom serving containers with specific pre-processing and post-processing code without needing to manually write Dockerfiles.","use_cases":["Deploying models that require raw input data transformation (e.g., text tokenization, image resizing) before prediction.","Formatting model outputs into specific business-logic structures (post-processing).","Serving Scikit-learn pipelines that include custom transformers.","Bundling specific Python packages\/dependencies that are not included in standard pre-built containers."],"not_used_when":["The model is a standard framework (TF, Sklearn, XGBoost) requiring no custom logic (use Pre-built Containers instead).","You need deep control over the OS, system-level libraries, or non-Python dependencies (build a full Custom Container from scratch).","You are running simple batch predictions where BigQuery ML would be more cost-effective."]}
{"product_name":"BigQueryClient","entity_type":"Library \/ SDK","ui":["Programmatic API (Code)"],"connected_to":["BigQuery Service","Cloud Storage","Google Cloud IAM","Pandas (Python library)"],"short_description":"The primary entry point object in Google Cloud Client Libraries (such as the Python SDK) used to authenticate, configure connections, and interact with the BigQuery API.","use_cases":["Executing SQL queries programmatically from backend applications","Loading data from local files or Cloud Storage into BigQuery tables","Streaming real-time data rows into BigQuery","Exporting query results directly to Pandas DataFrames for analysis"],"not_used_when":["Performing ad-hoc, one-off manual queries (use the BigQuery Cloud Console UI instead)","Writing simple shell automation scripts (use the 'bq' command-line tool instead)","Using JDBC or ODBC drivers which handle the client connection internally"]}
{"product_name":"Vertex AI Vision","entity_type":"Managed Service","ui":["Console UI (Drag-and-drop Application Builder)","REST API","gcloud CLI"],"connected_to":["Vertex AI (Model Registry)","BigQuery","Cloud Storage","Pub\/Sub","Cloud Functions"],"short_description":"A serverless, managed environment that enables users to ingest, process, and analyze real-time video streams using computer vision by connecting pre-trained or custom models via a low-code interface.","use_cases":["Retail analytics (occupancy counting, queue management, heatmapping)","Manufacturing safety (PPE detection, intrusion detection)","Traffic monitoring and vehicle analytics","Visual quality inspection and defect detection on assembly lines"],"not_used_when":["Analyzing individual static images (use Cloud Vision API instead)","Performing batch processing on historical video archives where real-time streaming is not required (use Cloud Video Intelligence API)","The solution requires strictly offline, on-device processing with absolutely no cloud connectivity","You require full manual control over the underlying GPU infrastructure and orchestration rather than a managed serverless environment"]}
{"product_name":"AutoML Entity Extraction","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Vertex AI UI)","REST API","gRPC API","Client Libraries (Python, Java, Node.js, etc.)","gcloud CLI"],"connected_to":["Vertex AI","Cloud Storage","Cloud Natural Language API"],"short_description":"A service that enables users to train custom machine learning models to identify and extract domain-specific entities (words or phrases) from text documents without writing model code.","use_cases":["Extracting specific clauses or terms from legal contracts","Identifying proprietary product codes or SKUs in support tickets","Parsing medical records for specific symptoms or treatments not covered by general models","Extracting custom metadata from financial invoices or receipts"],"not_used_when":["The entities to be extracted are common\/general (e.g., Person, Location, Organization, Date) - use the pre-trained Cloud Natural Language API instead","You do not have a sufficient dataset of labeled examples for training","You require generative capabilities or complex reasoning (use Large Language Models like Gemini instead)","You need immediate results without the time investment of training and deploying a custom model"]}
{"product_name":"Cloud Shell","entity_type":"Managed Service","ui":["Web Console","CLI","Integrated Code Editor"],"connected_to":["Compute Engine","Cloud Storage","Google Kubernetes Engine","Cloud Source Repositories","Cloud Build","IAM"],"short_description":"An interactive, browser-based shell environment for managing Google Cloud resources, featuring a persistent 5GB home directory and pre-installed tools like the Cloud SDK, git, and language runtimes.","use_cases":["Running ad-hoc gcloud commands without local installation","Developing, building, testing, and deploying applications directly from the browser","Managing infrastructure via Terraform or deployment scripts","Quickly editing files using the built-in Cloud Shell Editor"],"not_used_when":["Running long-running background processes or servers (sessions time out after inactivity)","Hosting production workloads or websites","Storing large amounts of data exceeding the 5GB persistent disk limit","Performing heavy computational tasks requiring high-performance CPUs or GPUs"]}
{"product_name":"TPU VMs","entity_type":"Compute \/ Infrastructure","ui":["Google Cloud Console","gcloud CLI","REST API","SSH","Client Libraries"],"connected_to":["Compute Engine","Cloud Storage","Vertex AI","VPC Network","Artifact Registry","Cloud Logging","Cloud Monitoring"],"short_description":"Virtual machines that run directly on the host machines connected to Tensor Processing Units (TPUs), providing users with root access to the TPU hardware for high-performance machine learning workloads.","use_cases":["Training large-scale deep learning models (e.g., LLMs, Transformers, Recommendation Systems).","High-throughput machine learning inference.","Research and development requiring direct access to TPU hardware for debugging and profiling.","Workloads utilizing JAX, PyTorch, or TensorFlow optimized for XLA (Accelerated Linear Algebra)."],"not_used_when":["Running general-purpose computing tasks (web hosting, databases) that do not involve heavy matrix multiplication.","The workload relies heavily on custom CUDA kernels (NVIDIA specific) that have not been ported to XLA\/TPU.","The machine learning model is small enough to be trained cost-effectively on CPUs or entry-level GPUs.","The application requires software or libraries that are strictly incompatible with the TPU architecture."]}
{"product_name":"TPUv3 Pod slices","entity_type":"Compute \/ Infrastructure","ui":["Google Cloud Console","gcloud CLI","Cloud TPU API"],"connected_to":["Compute Engine","Cloud Storage","Google Kubernetes Engine (GKE)","Vertex AI","VPC Network"],"short_description":"A configuration of Google's third-generation custom machine learning accelerators where users provision a specific fraction (slice) of a full TPU Pod supercomputer, connected via high-speed inter-chip interconnects for massive parallel processing.","use_cases":["Training massive Large Language Models (LLMs) like BERT or GPT variants","Large-scale distributed training of computer vision models","Research requiring supercomputer-scale matrix multiplication performance","Workloads requiring high-bandwidth memory and low-latency communication between chips"],"not_used_when":["Training small models that fit comfortably on a single GPU or single TPU board","Running general-purpose code not optimized for XLA (Accelerated Linear Algebra)","Performing low-latency real-time inference (single chips are usually preferred over Pod slices)","Workloads heavily dependent on custom CUDA kernels that cannot be easily translated to TPU operations"]}
{"product_name":"TPUEmbedding API","entity_type":"API","ui":["API (Python via TensorFlow or JAX)"],"connected_to":["Cloud TPU","Compute Engine","Vertex AI","Cloud Storage"],"short_description":"A specialized interface designed to accelerate large-scale embedding lookups and updates on Google Cloud TPUs by utilizing dedicated hardware (SparseCores) to handle tables that exceed standard memory limits.","use_cases":["Training massive recommendation systems (e.g., DLRM)","Click-through rate (CTR) prediction models","Natural Language Processing with extremely large vocabularies","Handling embedding tables that are too large to fit in the High Bandwidth Memory (HBM) of accelerator chips"],"not_used_when":["Running models on GPUs or CPUs (hardware incompatible)","Embedding tables are small enough to fit comfortably in standard accelerator memory","The model architecture does not utilize sparse features or embeddings","Using ML frameworks that do not have TPU-specific compiler support"]}
{"product_name":"AutoML Translation","entity_type":"Machine Learning Service","ui":["Google Cloud Console (Web UI)","REST API","gcloud CLI","Client Libraries (Python, Java, Go, etc.)"],"connected_to":["Cloud Storage (for storing training datasets)","Cloud Translation API (Basic\/Advanced)","Vertex AI (as part of the unified AI platform)"],"short_description":"A service that enables developers and translators to train custom machine learning models for translation using their own data (sentence pairs) to improve accuracy for domain-specific terminology and style without needing ML expertise.","use_cases":["Translating technical manuals with industry-specific jargon (e.g., medical, legal, engineering)","Localizing software or games that require specific glossaries","Maintaining consistent brand voice and style across different languages in marketing materials","Improving translation quality for language pairs where the standard model underperforms on specific content"],"not_used_when":["The standard pre-trained Cloud Translation API already provides sufficient quality","You do not have enough training data (requires a minimum of 1,000 sentence pairs, though more is recommended)","Cost is a primary constraint (training and prediction with custom models is more expensive than the standard API)","You require immediate implementation without the time investment for training and evaluating a model"]}
{"product_name":"Translation Hub","entity_type":"Managed Service","ui":["Translation Hub Portal (End-user UI)","Google Cloud Console (Admin UI)","REST API"],"connected_to":["Cloud Translation API","Cloud Storage","Vertex AI (AutoML for custom models)","Identity and Access Management (IAM)"],"short_description":"A self-service document translation platform designed for organizations that allows business users to translate documents at scale while preserving layout and formatting, with support for custom glossaries and human post-editing.","use_cases":["Self-service translation for non-technical employees (HR, Legal, Marketing)","Translating formatted documents (PDF, DOCX, PPTX) while retaining original layout","Enterprise localization workflows requiring human-in-the-loop (post-editing)","Centralized management of translation costs and resources across an organization"],"not_used_when":["Real-time, synchronous translation of short text strings is required (use Cloud Translation API)","Translating dynamic website content or mobile app interfaces programmatically","You require a free, consumer-grade solution for casual use (use Google Translate)","Deep integration into a custom CMS is required without a portal interface"]}
{"product_name":"BigQuery Studio","entity_type":"Developer Platform","ui":["Web UI (Google Cloud Console)"],"connected_to":["BigQuery","Vertex AI","Colab Enterprise","Cloud Storage","Dataform","Gemini for Google Cloud"],"short_description":"A unified workspace within the Google Cloud Console that combines SQL editing, Python notebooks (via Colab Enterprise), and asset management to streamline data analytics and AI workflows.","use_cases":["Interactive SQL querying and exploratory data analysis","Developing and running Python notebooks for data science directly in the console","Visualizing query results and generating charts","Collaborating on code assets and saved queries"," integrating data analysis with Vertex AI foundation models"],"not_used_when":["Building programmatic, customer-facing applications (use BigQuery Client Libraries\/API instead)","You require a strictly local development environment (use VS Code or local IDEs)","Orchestrating complex, dependency-heavy production pipelines (use Cloud Composer or Workflows)","You need to process data entirely offline"]}
{"product_name":"Vertex AI Data Labeling Service","entity_type":"Managed Service","ui":["Google Cloud Console","Vertex AI API","Vertex AI SDK (Python)","gcloud CLI"],"connected_to":["Cloud Storage","Vertex AI Datasets","Vertex AI AutoML","Vertex AI Custom Training"],"short_description":"A managed service within the Vertex AI platform that allows users to request human labeling for image, video, text, and audio datasets to create ground truth data for machine learning models.","use_cases":["Annotating images for object detection (bounding boxes), segmentation, or classification","Text sentiment analysis and entity extraction","Video object tracking and action recognition","Generating high-quality training data specifically for AutoML models"],"not_used_when":["You require immediate, real-time labeling results (human labeling introduces latency)","You already possess high-quality, pre-labeled ground truth data","Data privacy regulations strictly prohibit any human access to the data by external vendors (even under NDA)","The dataset is trivial in size and can be labeled internally with minimal effort","You are looking for purely algorithmic\/automated labeling without human verification"]}
{"product_name":"Google Cloud Console","entity_type":"Developer Platform","ui":["Graphical User Interface (GUI)","Embedded Command Line (Cloud Shell)"],"connected_to":["Compute Engine","Cloud Storage","Google Kubernetes Engine","Cloud IAM","Cloud Billing","Cloud Logging","Cloud Monitoring","Virtually all Google Cloud Services"],"short_description":"The central web-based portal used to deploy, scale, and manage Google Cloud projects, resources, and services through a graphical interface.","use_cases":["Visually provisioning and configuring resources (VMs, Buckets, Databases)","Setting up billing accounts and analyzing cost reports","Managing user permissions and IAM roles","Viewing logs, metrics, and monitoring dashboards","Quick prototyping or performing one-off administrative tasks"],"not_used_when":["Strict Infrastructure as Code (IaC) practices are enforced (e.g., using Terraform)","Automating CI\/CD pipelines and deployments","Performing large-scale, repetitive bulk operations where scripting is more efficient","Audit requirements demand version-controlled infrastructure definitions rather than manual 'ClickOps'"]}
{"product_name":"Vertex AI Agent Builder","entity_type":"Managed Service","ui":["Google Cloud Console (No-code\/Low-code UI)","REST API","RPC API","Client Libraries (Python, Node.js, Java, Go)"],"connected_to":["Vertex AI (Gemini, PaLM models)","Dialogflow CX","Cloud Storage (GCS)","BigQuery","Cloud SQL","Firestore","Identity and Access Management (IAM)"],"short_description":"A unified orchestration platform that enables developers to build and deploy generative AI agents and enterprise search applications by grounding foundation models in enterprise data.","use_cases":["Building RAG (Retrieval-Augmented Generation) customer service chatbots","Creating internal enterprise search engines for wikis and documentation","Developing transactional agents that execute tasks via API tools","Summarizing and analyzing large document sets"],"not_used_when":["You only need raw access to a Foundation Model without orchestration, grounding, or search capabilities (use Vertex AI Studio\/API directly)","You require a strictly deterministic, rule-based system with absolutely no generative variability","You need to fine-tune a model's weights manually from scratch (use Vertex AI Training)","The solution requires an entirely on-premise deployment with no cloud connectivity"]}
{"product_name":"Vertex AI Vector Search","entity_type":"Managed Service","ui":["Google Cloud Console (Web UI)","REST API","gRPC API","gcloud CLI","Python SDK (Vertex AI SDK)"],"connected_to":["Cloud Storage","Vertex AI Embeddings","BigQuery","Virtual Private Cloud (VPC)","Vertex AI Pipelines"],"short_description":"A fully managed, high-scale vector database service that performs approximate nearest neighbor (ANN) search to find similar items based on vector embeddings, utilizing Google's ScaNN algorithm.","use_cases":["Retrieval-Augmented Generation (RAG) for GenAI applications","Semantic search engines (text, image, or video)","Recommendation systems (product recommendations, content personalization)","Ad targeting and matchmaking","Anomaly detection"],"not_used_when":["Exact keyword search or strict boolean filtering is the primary requirement (use Elasticsearch or SQL)","The dataset is very small (e.g., < 10,000 vectors), where local libraries like Faiss or ScaNN would be more cost-effective","You require a primary transactional database (OLTP) with ACID compliance","You need to store large blobs of raw text\/data rather than just the vector representations and metadata"]}
{"product_name":"Colab Enterprise","entity_type":"Developer Platform","ui":["Web UI (Google Cloud Console)","Vertex AI SDK (Python)","REST API"],"connected_to":["Vertex AI","BigQuery","Cloud Storage","Identity and Access Management (IAM)","Dataform","Gemini for Google Cloud"],"short_description":"A managed notebook environment integrated into Vertex AI that combines the collaborative features and ease of use of Google Colab with enterprise-grade security, compliance, and compute management capabilities.","use_cases":["Collaborative exploratory data analysis (EDA) and machine learning model prototyping.","Writing and executing code that integrates directly with BigQuery data.","Developing and testing Generative AI applications using Gemini and other foundation models.","Sharing notebooks securely across an organization with granular IAM controls."],"not_used_when":["Deploying production-grade, low-latency real-time model serving endpoints (use Vertex AI Prediction instead).","Running complex, unattended, multi-step production MLOps pipelines (use Vertex AI Pipelines instead).","Personal, non-commercial hobby projects where the standard free Google Colab is sufficient.","Strict offline development is required."]}
{"product_name":"Model Garden","entity_type":"Service Feature","ui":["Google Cloud Console (Web UI)","Vertex AI SDK (Python)","REST API"],"connected_to":["Vertex AI","Vertex AI Studio","Vertex AI Prediction","Colab Enterprise","Vertex AI Pipelines"],"short_description":"A curated collection within Vertex AI that serves as a library for discovering, testing, customizing, and deploying foundation models, including Google's proprietary models (e.g., Gemini, PaLM) and open-source models (e.g., Llama, Mistral).","use_cases":["Discovering and evaluating foundation models for specific tasks (text, vision, code)","One-click deployment of open-source models to Vertex AI endpoints","Fine-tuning foundation models with custom datasets","Launching notebooks to experiment with pre-trained models"],"not_used_when":["Building traditional machine learning models from scratch (use Vertex AI Training)","Managing versions of your own custom-trained private models (use Vertex AI Model Registry)","Storing container images (use Artifact Registry)","You require strictly offline, local-only model execution without cloud dependencies"]}
{"product_name":"Vertex AI managed datasets","entity_type":"Service Feature","ui":["Google Cloud Console (Web UI)","Vertex AI API (REST\/gRPC)","Vertex AI SDK for Python","gcloud CLI"],"connected_to":["Cloud Storage","BigQuery","Vertex AI AutoML","Vertex AI Custom Training","Vertex AI Data Labeling"],"short_description":"A centralized resource within Vertex AI designed to import, analyze, and manage structured and unstructured data (image, text, video, tabular) specifically for training machine learning models.","use_cases":["Training AutoML models (requires managed datasets)","Organizing data for custom model training with unified metadata","Managing data splits (training, validation, test) automatically","Facilitating human labeling tasks for raw data"],"not_used_when":["Storing generic application files or backups (use Cloud Storage)","Performing general-purpose data warehousing or SQL analytics (use BigQuery)","Handling real-time streaming data ingestion","The training workflow requires highly complex, dynamic on-the-fly data generation that cannot be pre-materialized or fits standard schemas"]}
